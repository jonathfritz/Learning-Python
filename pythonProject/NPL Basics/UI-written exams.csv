Title;Transcript
Unternehmensstrategie von Mavallon;""
Vergleich von JSON- und XML-Schema;"3 Einleitung
Seit dem Beginn der Softwareentwicklung werden Algorithmen und Datenstrukturen stetig komplexer. Diese steigende Komplexität erfordert strukturiertere Software-Engineering Me-thoden, um die Entwicklung von Software weiterhin in kontrollierten und berechenbaren Strukturen managen zu können (Metzner, 2020, S. 9). 
Selbst heute gelingen nur rund 11-39 % der IT-Projekte vollständig, während gar 9-29% der Projekte als gescheitert angesehen werden (ebd. S. 11.). Aus dieser weiterhin schlechten Erfolgsquote werden in der Wissenschaft folgende Schlussfolgerungen gezogen. Software-entwicklung funktioniert heute nicht mehr ohne ein strukturiertes, geplantes Vorgehen. Es ist zwar weiterhin Kreativität bei der Lösungssuche gefragt, aber ohne eine wohldefinierte Vor-gehensweise ist die Chance eines Scheiterns zu groß (ebd. S.11). 
Aus diesen Gründen entstanden standardisierte Vorgehensweisen zur Erstellung von Soft-ware wie das Scrum- oder das V-Modell. Und während IT-Systeme auf einem globalen und unternehmensinternen Level immer komplexer wurden, entstanden weitere neue Standards, um immer neue und weitere Bereiche der Softwareentwicklung in kontrollierte Bahnen zu lenken. Besonders wichtig sind solche Standards im EDI-Bereich. EDI steht für Electronic Data Interchange und „dient zur Übertragung von Geschäftsdokumenten zwischen Unter-nehmen in einem Standardformat“ (IBM, n. d.). Im EDI-Bereich stellt sich die große Frage, wie Unternehmen ihre IT-Schnittstellen gestalten sollen, damit die verschiedenen IT-Systeme miteinander kommunizieren können. Wenn jedes Unternehmen seine eigene Lösung entwi-ckelt, müssten jeder ihrer Geschäftspartner ein oder mehrere speziell auf sie zugeschnittene Datenformate entwickeln – ein unverhältnismäßig hoher Aufwand.
Gerade im Bereich der Kommunikation ist eine gemeinsame Basis für die geltende Semantik und Syntax von zentraler Bedeutung. Ohne eine allgemeingültige Art und Weise der Kommu-nikation ist dies nicht möglich. Diesem Ziel widmen sich die drei Standards, deren Verwen-dung in dieser Arbeit untersucht und verglichen wird. Dabei handelt es sich um REST API, ein Design für die technische Gestaltung von Schnittstellen, sowie JSON und XML-Schema, zwei standardisierte Datenformate für den Datenaustausch zwischen IT-Systemen. Während das REST-API Design die technische Grundlage für eine Schnittstelle bildet, regeln die JSON- und XML-Schema die Gestaltung und Prüfung der Datenformate, die über die Schnittstelle zwischen den Geschäftspartnern ausgetauscht werden. Während eine API also dafür sorgt, dass Daten ausgetauscht werden können, regeln Schemas die Art und Weise wie Daten ausgetauscht werden sollen.
Doch welches der beiden standardisierten Datenformate ist besser für den Datenaustausch geeignet? Während XML-Schemata bereits seit vielen Jahren im EDI eingesetzt werden, ist der Einsatz von JSON-Schema erst in den vergangenen Jahren populär geworden, findet seitdem aber eine zunehmende Verbreitung. In dieser wissenschaftlichen Arbeit sollen die beiden Formate auf verschiedene Aspekte hin miteinander verglichen werden, um so die Frage zu klären, welches Datenformat besser im Zusammenspiel mit auf REST basierenden API-Schnittstellen verwendet werden soll. 
In einer Zeit, in welcher der automatisierte Datenaustausch zwischen Unternehmen immer weiter zunimmt (Bitkom, 2023), helfen diese Art von Vergleichen bei der Entscheidungsfin-dung. Unternehmen werden sich entscheiden müssen, welche Formate sie bevorzugt einset-zen, sodass ihre Systeme und Datenstrukturen sich möglichst kosten effizient harmonisieren lassen und die Kommunikation mit externen Partnern keine Komplikationen verursacht. 

4 Theoretische Fundierung 
4.1 REST API
Das theoretische Grundgerüst dieser Arbeit bilden die offiziellen Standards XML-Schema und JSON-Schema sowie zu einem kleineren Teil die Definition einer Rest API. Nach einer klei-nen Einführung in das Thema REST API, werden die beiden Schemata veranschaulicht. 
Eine API ist eine Programmierschnittstelle (application programming interface) und definiert die Art und Weise wie Software mit fremder Software kommuniziert (Frank R, Strugholtz S, Meise F, 2022, S. 40). Sie sind somit keine eigene Softwareapplikation, sondern Teil einer Applikation, die mit anderen Applikationen kommunizieren muss.  Das REST steht für „Re-presentational State Transfer“ und wurde vom Informatiker Roxy Fielding im Jahr 2000 in seiner Dissertation entwickelt. Es handelt sich dabei um eine Art Architekturbeschränkung, die vorgibt, wie APIs gestaltet werden sollen. Diese Beschränkungen schreiben ein einheitli-ches Interface vor. Es sollten nur die HTTP-Verben „Get“, „Put“, „Post“ und „Delete“ genutzt werden können, um Informationen zu erhalten oder zu verändern (Abts, 2019, S. 260-261). Des Weiteren soll jede Anfrage an die API zustandslos sein, also selbstbeschreibend und un-abhängig von anderen Anfragen funktionieren. Dabei ist auch die Rollenverteilung von zentra-ler Bedeutung. Der anfragende Client muss sich im Rahmen der Kommunikation vom ant-wortenden Server unterscheiden. Es muss sich um zwei unterschiedliche Systeme handeln. Zu guter Letzt muss die Kommunikation Cachefähig sein. Die Darstellung der Daten kann somit jederzeit gespeichert und wieder aufgerufen werden (ReadMe, 2016). Falls diese Be-dingungen von einer API erfüllt werden, gilt diese als REST-API. Viele große Akteure im In-ternet haben sich auf die Einhaltung dieser Beschränkungen geeinigt, sodass ihre Anwendung heute weit verbreitet ist. 

4.2 XML-Schema
XML ist eine Metasprache für die Markierung von textuellen Dokumenten. Es ist als universa-les Format für den Austausch von strukturierten Informationen gedacht, das in einer für Ma-schinen und Menschen lesbaren Form vorliegt.. XML basiert auf SGML. Diese Standardized Generalized Markup Language wurde 1989 von der International Organisation for Standardi-sation (kurz ISO) veröffentlicht (DIN, n. d., Anmerkung: Der damals von der ISO veröffent-lichte Standard (ISO 8879) kann hier eingesehen werden: https://www.din.de/en/getting-involved/standards-committees/nia/publications/wdc-beuth:din21:736498 ).
Das World Wide Web Consortium nahm SGML als Grundlage, verschlankte den Standard zu einem auf das Web ausgerichteten Datenformat und nannte es XML. Noch heute entwickelt das Konsortium den XML-Standard weiter und veröffentlicht regelmäßig verbesserte Versio-nen (W3C, 2016, Anmerkung: Der aktuelle XML-Standard kann hier eingesehen werden: https://www.w3.org/XML/  ). Im Rahmen dieser Weiterentwicklung wurde auch die Anwen-dungssprache XML-Schema veröffentlicht. Dabei handelt es sich um eine Möglichkeit, den Inhalt einer XML-Datei auf seine inhaltliche Richtigkeit zu überprüfen. 
Wenn beispielsweise eine REST-API die hier gezeigte Nachricht (Abb. 1) empfängt, wird das in ihr hinterlegte XML-Schema aufgerufen. Das Schema prüft die einzelnen Werte auf Ihre Richtigkeit. Durch die Validation kann sichergestellt werden, dass die Preise stimmen, eine Postleitzahl immer fünfstellig ist und vieles mehr. Schema stellen damit eine hohe Qualität im Datenaustausch her und sorgen dafür, dass fehlerhafte Nachrichten den Betrieb der IT-Systeme nicht stören. 
4.3 JSON-Schema
Das zweite zu untersuchende Datenaustauschformat in dieser Arbeit ist JSON (JavaScript Objekt Notation). Genau wie XML zielt es darauf ab, den Datenaustausch mithilfe einer schlanken, menschenlesbaren Struktur zu standardisieren und wurde in den frühen 2000ern entwickelt. Der offizielle JSON-Standard wird von ECMA verwaltet, einer privatwirtschaftli-chen 
Normierungsorganisation (ECMA, 2027). Die aktuelle JSON-Version „ECMA-404“ stammt aus dem Jahr 2017 (ebd.) . Auf der Grundlage dieses Datenformates hat eine Gruppe von Entwicklern seit 2010 ein JSON-Schema veröffentlicht (JSON-Schema org, 2010). Das Schema wurde seitdem kontinuierlich weiterentwickelt und befindet sich heute in seinem neunten Draft (JSON-Schema org, n. d.).
An dieser Stelle ist jedoch anzumerken, dass es sich beim JSON-Schema noch um keinen offiziell anerkannten Standard handelt (jdesrosiers, 2022) . Stattdessen handelt es sich wei-terhin um eine Gruppe aus unabhängigen Entwicklern, die ohne eine finanzielle Gegenleis-tung eine Open Source Softwarelösung entwickeln. Der fehlende Charakter eines offiziellen Standards hat JSON-Schema aber mitnichten davon abgehalten eine immer größere Ver-breitung zu finden. Es gibt bereits eine große Anzahl an Softwarelösungen, die mit dem JSON-Schema arbeiten (JSON-Schema org, n. d.). Populärstes Beispiel ist Postman, der bekannteste Anbieter von Testfunktionen für APIs (Viotti J C, 2023). Aufgrund der großen Beliebtheit und weiten Verbreitung des JSON-Schemas gilt das „Draft 9“ ebenso wie die De-signvorgaben einer Rest API und dem offiziell geltenden XML-Schemas als theoretische und technische Grundlage dieser wissenschaftlichen Arbeit. 

5 Methodik/ Forschungsdesign
Das Hauptziel dieser Forschungsarbeit ist es, einen umfassenden Vergleich zwischen JSON-Schema und XML-Schema durchzuführen. Durch den systematischen Vergleich anhand eines Praxisbeispiels sollen generalisierbare Kenntnisse über die Vor- und Nachteile der bei-den Schemasprachen gewonnen werden. Es ist das Ziel festzustellen, welche der beiden Sprachen besser geeignet ist, um REST API-Antworten und Anfragen zu validieren. 
Der Vergleich wird im Rahmen eines Praxisbeispiels durchgeführt. Es werden zwei Schema-ta erstellt, die beide komplexe Bedingungen aufstellen, welche die zu validierenden Nachrich-ten erfüllen müssen. Die Schemata werden entwickelt, getestet und ihr Einsatz anschließend mithilfe von Testdaten simuliert. Bei einigen Arbeitsschritten wird die Software GEFEG.FX eingesetzt, welche auf die Entwicklung und Dokumentation von Schemata spezialisiert ist. Auf diese Weise können die beiden Schemata in jeder Phase ihren Lebenszyklen verglichen werden. Die vergleichende Untersuchung konzentriert sich auf mehrere Aspekte.
Zuerst werden die beiden Schemata auf ihre Ausdruckskraft und Flexibilität verglichen. Es wird festgestellt, wie gut die Schemata dazu in der Lage sind, komplexe Datenstrukturen und verschachtelte Hierarchien in den REST API-Antworten zu beschreiben. Danach wird ihre Lesbarkeit und Wartbarkeit eingehender analysiert. Je einfacher ein Entwickler das Schema verstehen und pflegen kann, desto besser eignet es sich für den Einsatz im Unternehmen.
Anschließend wird soweit möglich noch auf die Performance, den Ressourcenverbrauch und die Interoperabilität der jeweiligen Schemata eingegangenen. Der Vergleich dieser Aspekte anhand des in dieser Arbeit durchgeführten Praxisbeispiels würden den Rahmen des Pra-xisprojekt sprengen. Komplexe IT-Systemen, wie die eines Großunternehmens, welche jeden Tag hunderttausende von Nachrichten versenden, empfangen und verarbeiten müssen, kön-nen in dieser Arbeit nicht simuliert werden. Aus diesem Grund werden an dieser Stelle auch auf Erkenntnisse aus der Fachliteratur zurückgegriffen. 
Bei der Interoperabilität geht es um die Fähigkeit einer Schema-Sprache, nahtlos mit gängi-gen Entwicklungswerkzeugen, Bibliotheken und Plattformen interagieren zu können (Reich, 2021, S. 1). Dies beeinflusst die Effizienz und den Erfolg der Implementierung. Auch die Per-formance hängt mit dieser Eigenschaft zusammen. Dabei handelt es sich um die Geschwin-digkeit und den Ressourcenverbrauch der Validierung. Je einfacher das Schema in ein Sys-tem integriert werden kann, desto schneller läuft normalerweise auch die Validierung alle ein-gehenden Nachrichten ab. 
Zum Schluss werden die Ergebnisse und Einblicke in die Vor- und Nachteile von JSON-Schema und XML-Schema bei der Validierung von REST API-Antworten noch einmal in Handlungsempfehlungen für Unternehmen und einem Fazit zusammengefasst. Dies kann Entwicklern und Organisationen helfen, fundierte Entscheidungen darüber zu treffen, welche Schema-Sprache am besten geeignet ist, um ihre spezifischen Anforderungen zu erfüllen (Anmerkung: Die ersten Seiten des Praxisprojektes von der Einleitung bis zum Forschungs-design wurden größtenteils aus dem Exposé übernommen, dass als Vorlage für dieses Pra-xisprojekt dient).

6 Entwicklungskonzept der API und Schemas
Die REST-API wird in der Programmiersprache Python entwickelt. Der Code wurde in meh-rere Klassen und ein Datenpaket für die „Exceptions“ unterteilt, um die API übersichtlicher zu gestalten und eine bessere Wartbarkeit zu gewährleisten. Dabei wurden zwei zusätzliche Klassen erstellt, die der API die beiden Schemata und eine Validierungsfunktion bereitstellen. In der Mainfunktion wird die API gestartet und der Post-Request aufgerufen. Der Programm-code der API kann in dem folgenden GitHub Repository eingesehen werden (GitHub-Link: https://github.com/jonathfritz/CustomDeclarationAPI )
Es ist jedoch hervorzuheben, dass es sich hierbei um eine eher rudimentäre API handelt, die sich nicht darauf konzentriert, einen Mehrwert für jeden Nutzer „Clienten“ zu geben. Stattdes-sen steht der Vergleich zwischen JSON und XML in dieser Arbeit im Vordergrund. Daher wurde der Ausarbeitung der API nicht mehr Zeit als nötig gewidmet und sich primär auf die Entwicklung, Implementierung und den operativen Einsatz der beiden Schemata konzentriert.
Die beiden Schemata werden basierend auf einem UML-Datenmodell erstellt, das eine grund-legende Struktur der zu nutzenden Datenelemente sowie ihre Hierarchie und Kardinalität vor-schreibt (Siehe Anhang 1). In den Datenmodellen sind auch die praktischen Anforderungen aus dem Fallbeispiel beschrien, dass in diesem Praxisprojekt genutzt wird. Es handelt sich um eine „Custom Declaration“, die beim grenzüberschreitenden Handel genutzt wird, um Waren beim Zoll des jeweiligen Landes zu deklarieren. Die beiden Schemata müssen die vergebene Struktur des Datenmodells sowie die praxisbezogenen Anforderungen aus der Zollerklärung soweit möglich darstellen können. Auf diese Weise müssen beide Schemata die identische Anforderung erfüllen und lassen sich adäquat vergleichen. Im Rahmen der Arbeit wird wie-derholt auf bestimmte Zeilen im Programmcode der beiden Schemata verwiesen. Da beide Schemata über 2000 Zeilen Code lang sind, wurden sie dieser Arbeit nicht direkt als Anhang hinzugefügt. Ebenso wie der Programmcode der API können die beiden Schemata im Git-Hub Repository eingesehen werden (Link: https://github.com/jonathfritz/CustomDeclarationAPI im Unterordner Schemas)
Der Client wird in dieser Arbeit durch Postmann eine Software zum Testen von APIs und Schema-Dateien genutzt. Postmann ist das etablierteste Tool zum Testen von APIs und kann daher problemlos für die Überprüfung der Testergebnisse eingesetzt werden. Durch seine Funktionsweise kann Postmann „Clients“ simulieren, welche auf die Dienste der API zugrei-fen. In diesem Praxisbeispiel sendet Postman valide und invalide XML- und JSON-Datenstrukturen an die API. Deren Reaktionszeit und andere Kriterien können dabei von Tool erfasst und verglichen werden. 
 

Während all dieser Arbeitsschritte lassen sich JSON und XML auf die zuvor definierten Ver-gleichskategorien untersuchen. Die dabei gewonnenen Erkenntnisse werden im nun folgen-den Kapiteln zusammengefasst. 

7 Vergleich von JSON- und XML-Schema
7.1 Ausdruckskraft und Flexibilität
Zuerst werden die beiden Schemata auf ihre Ausdruckskraft und Flexibilität verglichen. Es wird festgestellt, wie gut die Schemata dazu in der Lage sind, die vorgegebene Datenstruktur wiederzugeben und welche Möglichkeiten die Schemata haben, die Datenstrukturen mit zu-sätzlichen Anforderungen anzureichern.
Denn neben den bereits vorgegebenen Informationen im Datenmodell (Siehe Anhang Nr.1) sind weitere Restriktionen erforderlich. So muss beispielsweise die Kardinalität, der Datentyp jedes einzelnen Datenelements und dessen Status definiert werden (Anmerkung: Ein Beispiel ist das Datenelement „Address“ im XML Schema Zeile 10-17. Es wird als „complexType“ Datentype definiert, dass aus fünf Unterelementen besteht wie zum Beispiel „Street“ oder „City“. Alle fünf untergeordneten Elemente sind optional, was durch „minOccurs=“0“ festge-legt wird). Zugleich müssen die Elemente teilweise mit einer Beschreibung versehen werden können, als hilfreiche Dokumentation für alle Nutzer des Schemas. Diese grundlegenden Funktionen werden von beiden Schemata in diesem Fallbeispiel problemlos erfüllt. Sowohl das XML- als auch das JSON-Schema unterstützen die gängigsten Datentypen wie „String“ oder Integer, können festlegen, welche Elemente zwingend vorhanden und welche nur optio-nal sind und können mit Kommentaren versehen werden, die sehr gut für Dokumentations-zwecke eingesetzt werden können. 
Beide Schemata sind somit sehr ausdrucksstark und haben keine Schwierigkeiten, komplexe Datenstrukturen darzustellen und diese auch zu validieren. XML sticht in diesem Bereich be-sonders hervor und bietet mehr Funktionalitäten an. Es kann fast jede denkbare Datenstruktur abbilden, von sehr simplen bis zu hoch komplexen. Diese Flexibilität kommt jedoch mit einer gewissen Komplexität in der Definition und Verarbeitung von Schemata. XML ermöglicht die Definition von Namensräumen, was die Modularität und Wiederverwendbarkeit von Schema-Definitionen in großen und komplexen Systemen fördert. Letztendlich bietet XML so viele Möglichkeiten, dass in dem Fallbeispiel nur ein kleiner Teil von diesen eingesetzt wurde. Im Allgemeinen scheint XML besser geeignet zu sein sehr spezifische Anforderungen umzuset-zen als JSON. 
Während in JSON alle Daten in Form von Elementen angelegt sind, erlaubt XML zusätzlich dein Einsatz von Attributen, also Eigenschaften, die einem Element zugeordnet sind (Anmer-kung: Siehe dafür Zeile 3007-3008 im XML-Schema). In den meisten Fällen stellt dies kein Problem für JSON da, weil Attribute alternativ als untergeordnete Elemente eines anderen Elements dargestellt werden können, ohne die Hierarchie der Daten oder deren Bedeutung falsch darzustellen. Dennoch ist dies zweifelllos eine Einschränkung für JSON. 
Des Weiteren gibt es bei XML zusätzliche Werkzeuge, mit denen sehr detailreiche Regeln in der Datenstruktur definiert werden können. So gibt es beispielsweise mit „Sequenz“ und „Choice“ Möglichkeiten, mehrere untergeordnete Elemente zu strukturieren. Schematron ist eine weitere Ergänzung zu XML-Schema. Während XML-Schema hauptsächlich strukturelle Regeln für XML-Dokumente definiert, ermöglicht Schematron die Definition von Geschäfts-regeln und anderen komplexen Validierungsbedingungen, die über die strukturellen Aspekte hinausgehen (Schematron, n.d.). JSON- und XML Schema haben die vorgebende Daten-struktur somit vollständig und ohne Einschränkungen darstellen können. XML-Schema be-wies dabei aber deutlich mehr Möglichkeiten und unterschiedliche Herangehensweisen, um die Aufgabe zu lösen. Aus diesem Grund besitzt es eine höhere Ausdruckskraft und Flexibili-tät als JSON.

7.2 Lesbarkeit
Beide Datenformate wurden mit dem Ziel entwickelt, für Menschen und Maschinen gleicher-maßen lesbar zu sein. Im Verhältnis zu anderen Datenaustauschformaten wie YAML oder Newline stechen XML und JSON mit einer hohen Lesbarkeit heraus. Dies lässt sich gut an-hand der genutzten Testdaten feststellen, die in dieser Arbeit genutzt wurden (Anmerkung: Die Testdaten sind in einem Unterordner des Repositories ebenso wie der Programmcode und die Schemata einzusehen). Trotz fehlender IT-Kenntnisse kann jeder Leser den Inhalt der Files verstehen und nachvollziehen, welche Information in dem jeweiligen File versendet wur-den. 
In XML-Dateien werden die Daten mithilfe von Start- und End Tags strukturiert. Dieses Vor-gehen kann die Lesbarkeit für komplexe Dokumente mit verschachtelten und hierarchischen Daten verbessern, insbesondere wenn Namenstags sorgfältig gewählt werden. Allerdings kann die Verbosität von XML, insbesondere bei tief verschachtelten Strukturen oder der Dar-stellung einfacher Daten, die Lesbarkeit beeinträchtigen, da mehr Text zur Darstellung dersel-ben Information benötigt wird. Wenn jedes Datenelement mit einem Start-Tag beginnen muss und einem End-Tag abgeschlossen wird, entsteht viel überflüssiger Text. Dies kann im abge-bildeten Beispiel aus dem entwickelten XML-Schema veranschaulicht werden.  Das Element „Communcation“ wird mit dem Tag „<xc: complexType“ begonnen und dem Tag „</xs:complexType>“ beendet. Ähnliches gilt für die Regel „choice“.
 

JSON-Files sind hingegen sehr einfach und minimalistisch gehalten. Dies erleichtert das Ver-ständnis für den menschlichen Leser. Die Darstellung von Objekten und Arrays ist intuitiv, und das Fehlen von Tags (im Gegensatz zu XML) trägt zu einer geringeren Verbosität bei. Die Testdateien und das JSON-Schema sind daher deutlich einfacher zu lesen und zu verstehen als ihr XML-Gegenstück. 
 

7.3 Wartbarkeit
Eine gute Wartbarkeit ist von entscheidender Bedeutung für Schemata im Speziellen und Software im Allgemeinen, da sie sicherstellt, dass Programme langfristig effektiv bleiben. Wartbarkeit bezieht sich darauf, wie einfach es ist, Software zu verstehen, zu entwickeln, zu ändern und zu erweitern, ohne dabei die Stabilität oder Funktionalität zu gefährden. Durch eine gute Wartbarkeit können Fehler leichter gefunden und behoben werden, neue Funktio-nen schneller implementiert und Anpassungen an veränderte Anforderungen oder Umgebun-gen vorgenommen werden. Dies führt zu geringeren Kosten, weniger Ausfallzeiten und einer insgesamt höheren Lebensdauer der Software, was für Unternehmen und Entwickler von entscheidender Bedeutung ist, um wettbewerbsfähig zu bleiben und den Wert ihrer Investitio-nen langfristig zu erhalten.
Bei der Analyse der Wartbarkeit fließen viele Erkenntnisse der vorangegangenen Kapitel mit ein. Die Flexibilität und Ausdruckskraft von XML gibt jedem Entwickler einen großen Hand-lungsspielraum bei der Ausgestaltung der Datenstrukturen. Die Komplexität erschwert jedoch den Einstieg, da sie viel Zeit zur Einarbeitung erfordert. Außerdem kann die Nutzung von Namensräumen oder Schematran die Komplexität der Datenstruktur zusätzlich erhöhen, auch wenn beide Funktionen im Rahmen des Fallbeispiels nicht eingesetzt wurden. Die Na-mensräume ermöglichen die einfache Wiederverwendbarkeit von Datenelementen oder komplexeren Datenelementgruppen. Die Wiederverwendbarkeit von bereits zuvor definierten Datenelementen kann aber auch mithilfe der „$ref“ Funktion erfüllt werden. Diese wird in den beiden Fallbeispielen auch für alle Datenelemente genutzt (Anmerkung: Im JSON-Schema wird diese Funktion beispielsweise in Zeile 7 und 11 genutzt).
Wegen all dieser Aspekte wurde für die Entwicklung des XML-Schemas in dieser Arbeit deut-lich mehr Zeit benötigt als für die Entwicklung des gleichen JSON-Schemas. Zukünftige Än-derungen würden beim XML-Schema mehr Zeitaufwand benötigen als beim JSON-Schema. Das Problem zeigt sich bereits beim direkten Vergleich der beiden Schemata. Das XML-Schemata besitzt eine Speichergröße von 49,5 MB und ist damit rund 1.340-mal größer als das JSON-Schema mit seinen 37 KB. Die Anzahl an Programmcodezeilen ist ein weiteres wichtiges Maß zum Vergleich von Programmen oder Datenformaten. Das JSON-Schema ist 2.221 Zeilen lang, während das XML-Schema auf rund 3.010 Zeilen kommt (Anmerkung: Die meisten Codezeilen sind nur Codelisten, eine Sammlung von wiederverwendbaren Code-fragmenten, die verwendet werden, um die Integration verschiedener Unternehmenssysteme und Anwendungen zu erleichtern). Bei diesen Größenunterschieden wird ein weiteres Mal der Nachteil der großen Ausdrucksstärke und Flexibilität deutlich, die XML bietet. In den meisten Fällen werden die vielen Möglichkeiten und Optionen für ein XML-Schema nicht benötigt und müssen trotzdem bei der Entwicklung berücksichtigt werden.
JSON deutlich einfachere Handhabung und Lesbarkeit erleichtern hingegen eine effiziente Wartbarkeit. Es ist kein tiefes Verständnis erforderlich, um ein JSON-Schema zu entwickeln. Dementsprechend wird weniger Zeit für die erforderlichen Arbeitsschritte benötigt.

7.4 Perfomance und Ressourcenverbrauch
Neben der Wartbarkeit stellt die Perfomance und der Ressourcenverbrauch in der Software-entwicklung eine entscheidende Rolle. Wenn eine API und das Schema in der Praxis einge-setzt werden, muss die API oftmals hunderte Anfragen pro Minute überprüfen und bei einer bestandenen Validierung an den Server weiterleiten. Damit das System nicht überlastet, muss eine Validierung schnell ablaufen und möglichst wenig Rechenkapazität beanspruchen. 
Im Rahmen des Fallbeispiels wurden zwei valide und zwei invalide XML- und JSON-Testfiles an die API gesendet und währenddessen die durchschnittliche Reaktionszeit der API gemes-sen. Anhand der Reaktionszeit unter ansonsten gleichbleibenden Bedingungen lässt sich gut ablesen, wie effizient die zwei verschiedenen Schemata bei Ihrer Kernfunktion sind. Die Er-gebnisse dieser Testversuche sind in der folgenden Tabelle zusammengefasst. 
Testdaten	Größe der Datei (in KB)	∅ Dauer von zehn
 Validierungen (in ms)
Invalid JSON-Testfile 1	1,5 	55 
Invalid JSON-Testfile 2	1,53 	58 
Invalid XML-Testfile 1	1,65 	30 
Invalid XML Testfile 2	1,62	29 
Valid JSON Testfile 1	1,45 		43 
Valid JSON Testfile 2	1,5 	42 
Valid XML Testfile 1	1,56 	15 
Valid XML Testfile 2	1,59	14 

Alle Testdateien unabhängig vom Dateiformat sind mit rund 1,5 KB annähernd gleich groß. Bei der Dauer der Validierung lassen sich jedoch größere Unterschiede zwischen den Da-teiformaten sowie validen, als auch invaliden Testdaten feststellen. Erfüllt eine Textdatei nicht die Anforderungen des Schemas, dauert der Validierung deutlich länger. Bei XML-Dateien rund doppelt so lange wie bei den Validen. Bei den JSON-Dateien sind es rund 15 Millisekun-den (ms) mehr. 
Des Weiteren benötigt die API für die Validierung von JSON-Dateien erheblich länger als für XML-Dateien. Mit 42 und 43 ms erfordert eine erfolgreiche Validierung über 25 ms länger als die einer XML-Datei. Dieses Ergebnis überrascht angesichts der komplexeren Syntax und Struktur einer XML-Datei. Trotz der Verbosität der XML-Dateien eigenen sie sich gemäß der Testergebnisse besser für API, bei denen eine schnelle Antwortzeit von Bedeutung ist.

7.5 Interoperabilität
Bei der Interoperabilität geht es um die Fähigkeit einer Schema-Sprache, nahtlos mit gängi-gen Entwicklungswerkzeugen, Bibliotheken und Plattformen interagieren zu können (Reich, 2021, S. 1). Dies beeinflusst die Effizienz und den Erfolg der Implementierung. Je einfacher das Schema in ein System integriert werden kann, desto weniger Ressourcen müssen in die Entwicklung und Implementierung der Schnittstelle in das jeweilige System fließen. 
Sowohl JSON als auch XML spielen eine wichtige Rolle bei der Förderung der Interoperabili-tät, indem sie Standards für den Datenaustausch bieten. Ihre Fähigkeit, mit verschiedenen Technologien und Plattformen zu interagieren, hat jedoch jeweils eigene Merkmale und Ein-schränkungen. JSON wird von einer Vielzahl von Programmiersprachen und Plattformen nativ unterstützt. In dieser Arbeit wurde, wie bereits erwähnt Python für die Programmierung der API eingesetzt. In Python stehen zwei Bibliotheken zur Verfügung, mit deren Komponen-ten sich JSON-Dateien validieren lassen. Die beiden Bibliotheken heißen „jsonschema“ (Py-thon Package Index, 2024, Anmerkung: Das Package wird auf GitHub veröffentlicht) und „fastjsonschema“ (horesjek, 2023, Anmerkung: Auch dieses Package wird auf GitHub veröf-fentlicht). Da das Testen mehrere dieser Bibliotheken den Rahmen dieser Arbeit sprengen würde, kam nur „jsonschema“ zum Einsatz. 
Durch die Zugänglichkeit so vieler Datenpakete in den gängigen Programmiersprachen wie Python lässt sich ohne Schwierigkeiten eine Interoperabilität von beinahe allen IT-Systemen gewährleisten. Gleiches gilt auch für XML. Wie bei JSON stehen die gleiche Anzahl an Biblio-theken zur Verfügung, um die Nutzung von XML-Schemata zu erleichtern. Sowohl „lxml“ (lxml, 2024) als auch „xmlschema“ (Python package index, 2024) stehen für diesen Zweck in Python zur Verfügung.
Des Weiteren verfügt XML über eine weitreichende Akzeptanz in Enterprise-Umgebungen. In zahlreichen Branchen haben sich in den vergangenen Jahrzehnten Standards für den Daten-austausch auf XML-Basis etabliert. So werden in international Zahlungsverkehr zwischen Banken alle Informationen in XML-Dateien ausgetauscht (Internationale Organisation für Normung (ISO), n.d) sowie im Einzelhandel die Informationen zwischen den Supermärkten und allen Lieferanten (GS1, n.d., Anmerkung: GS1 ist eine internationale Normierungsorgani-sation, die auf den Einzelhandel ausgerichtet ist). JSON-Datenformate werden nicht in diesen Ausmaßen für den standardisierten Datenaustausch zwischen Unternehmen genutzt. 
So wird auch in dieser Vergleichskategorie wieder die unterschiedliche Ausrichtung der bei-den Datenformate deutlich. Während XML genutzt wird, um komplexe Geschäftsregeln gan-zer Branchen standardisiert abzubilden, wird JSON vor allem bei weniger anspruchsvollen, aber dafür umso zahlreicheren Web-Applikationen eingesetzt. In ihrem jeweiligen Bereichen führen die Stärken der beiden Datenformate zu einer besseren Interoperabilität. 

8 Handlungsempfehlungen
Basierend auf den Erkenntnissen aus dem Hauptteil lassen sich folgende Handlungsempfeh-lungen für den Einsatz von JSON- und XML Schemata ableiten. Bei der Entwicklung von APIs mit sehr komplexen Anforderungen, insbesondere solchen, die eine Vielzahl von ver-schachtelten Hierarchien und komplexen Validierungsregeln erfordern, erscheint die Verwen-dung von XML als die angemessenere Wahl. Die XML-Syntax bietet eine höhere Ausdrucks-kraft und Flexibilität, um auch die anspruchsvollsten Datenstrukturen zu modellieren. Darüber hinaus ermöglicht XML die Definition detaillierter Validierungsbedingungen über Werkzeuge wie Schematron, was bei komplexen Geschäftsregeln von Vorteil sein kann.
Für APIs, die ein hohes Anfrageaufkommen bewältigen müssen und bei denen die Reakti-onszeit entscheidend ist, empfiehlt sich ebenfalls die Nutzung von XML. Dies kann zu einer besseren Performance führen, insbesondere bei hohen Lasten. Für alle anderen Anwen-dungsfälle ist die Verwendung von JSON zu bevorzugen. Wegen seiner einfacheren Hand-habung in jeglicher Hinsicht, lassen sich die Schemata schneller und günstiger in JSON ent-wickeln.

9 Fazit
Während des Vergleichs der beiden Schemata wurden die Unterschiede, Vor- und Nachteile sowie die richtigen Anwendungsfälle für die beiden Datenformate besser. Keines der beiden Datenformate ist in jeder Hinsicht dem anderen überlegen. 
Beim Vergleich der Ausdruckskraft und Flexibilität hatte XML deutlich mehr anzubieten als JSON. Dafür zeichnete sich JSON durch seine bessere Lesbarkeit aus, die es selbst Einstei-gern erlaubt, den Inhalt einer JSON-Datei zu verstehen. Es zeigte sich, dass JSON eine Rolle als Allrounder einnimmt, wobei Einfachheit und Benutzerfreundlichkeit im Vordergrund ste-hen. Dies wurde in der nächsten Vergleichskategorie „Wartbarkeit“ noch deutlicher. Der Ein-stieg in JSON-Schema gelingt so schnell und führte ohne größere Schwierigkeiten zum an-gestrebten Ergebnis
Auf der anderen Seite zeigt sich XML als komplexes und kompliziertes Datenformat, das mehr Einarbeitung und Entwicklungszeit einfordert. Es erfordert mehr Aufwand in Wartung und Entwicklung, leistet aber auch mehr und kann selbst die anspruchsvollsten Anforderun-gen erfüllen. Des Weiteren zeigte es beim Performancetest ein besseres Ergebnis als JSON.
Insgesamt können wir festhalten, dass die Wahl zwischen JSON und XML von den spezifi-schen Anforderungen des jeweiligen Anwendungsfalls abhängt. JSON ist die bevorzugte Op-tion für einfache Strukturen und schnelle Implementierungen, während XML für komplexe Datenmodelle und anspruchsvolle Validierungsregeln besser geeignet ist. Solange sich jeder Nutzer dieser Stärken und Schwächen der beiden Datenformate bewusst ist, können in der Softwareentwicklung bei der Auswahl des passenden Datenformates die richtige Entschei-dung getroffen werden. Die Wahl zwischen JSON und XML hängt letztendlich von den spezi-fischen Anforderungen des Projekts und den Präferenzen des Entwicklungsteams ab. "
Bilanzanalyse von SAP;"4 Einleitung
Seit 2010 nimmt die Anzahl an Unternehmenskäufen in Deutschland stetig zu (DIHK-Report, 2015). Investoren und Unternehmen kaufen die Anteile anderer Unternehmen, um in neue Märkte einzusteigen, Synergieeffekte zu verstärken oder einfach nur um das Eigenkapital gewinnbringend zu diversifizieren. Beim Entscheidungsprozess und der Frage, ob es sich für einen Investor lohnt, in ein Unternehmen zu investieren, wird immer eine Bilanzanalyse durchgeführt.
Die Bilanzanalyse hat sich dabei zu einem unverzichtbaren Werkzeug entwickelt, mit dessen Hilfe das finanzielle Wohlergehen eines Unternehmens überprüft werden kann. Anhand von Kennzahlensystemen und anderer Methoden wird die finanzielle Leistungsfähigkeit des zu untersuchenden Unternehmens gemessen. Bei einem guten Ergebnis kann der Investor den Kauf von Anteilen weiterhin in Erwägung ziehen, bei schlechten Indikatoren, wie einer geringen Liquidität oder einer Verringerung der Eigenkapitalrentabilität, sollte von einem Kauf eher abgesehen werden.
Auch das mittelständische Unternehmen GEFEG mbH zieht es in Erwägung, Anteile eines börsennotierten Unternehmens zu kaufen. GEFEG ist ein mittelständisches Unternehmen mit rund 30 Angestellten, welches im aktuellen  Jahresabschluss von 2020 über ein Eigenkapital von 443.814,46 € (Bundesanzeiger, 2022) bei einer Eigenkapitalquote von 20,25 % verfügt. Es besitzt demnach über begrenzte Mittel, um größere Anteile von börsennotierten Unternehmen zu kaufen, die in der Regel über deutlich mehr Kapital verfügen. Das Ziel ist demnach keine Übernahme oder strategische Minderheitsbeteiligung, die GEFEG einen größeren Einfluss in einem anderen Unternehmen erbringen würde. Stattdessen sollen die Anteile nur im Hinblick auf einen potenziellen Gewinn erworben werden – entweder in Form von Ausschüttungen oder einer Wertsteigerung der erworbenen Anteile. Ehrgeizigere Zielsetzungen kommen wegen des vergleichsweise geringen verfügbaren Kapitals nicht infrage.
Als potenzielles Ziel eines solchen Erwerbs wurde die SAP SE auserkoren. Genau wie GEFEG ist das Unternehmen im IT-Sektor tätig. Während GEFEG Werkzeuge entwickelt, um den Datenaustausch zwischen Unternehmen zu automatisieren, entwickelt SAP Software zur Abwicklung sämtlicher Geschäftsprozesse. Oftmals werden die Werkzeuge von GEFEG genutzt, um Schnittstellen zwischen verschiedenen ERP-Systemen zu designen. Beide Unternehmen setzen dabei auf standardisierte Datenformate und einen ähnlichen Kundenstamm – auch wenn die Anzahl der SAP-Kunden sehr viel größer ist. Aufgrund dieser Bezugspunkte in der Geschäftstätigkeit der beiden Unternehmen, zieht GEFEG den Erwerb von Unternehmensanteilen der SAP SE in Erwägung. Im Rahmen dieses Praxisprojekts soll geklärt werden, ob GEFEG tatsächlich Aktien von SAP erwerben oder von einer solchen Investition lieber absehen sollte. Zu diesem Zweck wird eine Bilanzanalyse durchgeführt.
Vor der tatsächlichen Analyse des Finanzberichts der SAP SE wird der aktuelle Forschungsstand zum Thema Bilanzanalyse veranschaulicht. Ausgehend vom aktuellen Stand der Forschung werden anschließend die wichtigsten Methoden der Bilanzanalyse behandelt. Im Hinblick auf die Perspektive eines Investors, die in dieser Arbeit eingenommen wird, werden jene methodischen Ansätze noch näher im Detail erläutert, die bei dieser Arbeit genutzt werden, um wertvolle Erkenntnisse zu gewinnen, die vor allem für Investoren von Interesse sind. Im Hinblick auf die angewendeten Methoden werden zudem deren Grenzen aufgezeigt, welche oft die Aussagekraft der Ergebnisse einschränken. Den Methoden der Bilanzanalyse und deren Grenzen und Möglichkeiten soll in dieser Arbeit eine größere Aufmerksamkeit gewidmet werden. Aus diesem Grund sind diese Teile der Arbeit umfangreicher als es in Praxisprojekten normalerweise üblich ist.
Anschließend werden die vergangenen Bilanzen und Finanzberichte der SAP SE analysiert und auf der Grundlage der dabei gewonnenen Erkenntnisse Handlungsempfehlungen für die GEFEG mbH aufgestellt. Zum Schluss werden die Ergebnisse der Arbeit in einem Fazit noch einmal zusammengefasst.

5 Forschungstand
Das Thema Bilanzanalyse ist in der Wirtschaft von enormer Bedeutung, egal ob es um unternehmensinterne Analysen, Akquisitionen oder den Aktienmarkt geht. Wegen der hohen Relevanz wird das Thema intensiv erforscht und regelmäßig neue Fachliteratur veröffentlicht. Die aktuellen Forschungsschwerpunkte können dabei grob auf drei Debatten aufgeteilt werden. Der erste Schwerpunkt ist die Weiterentwicklung und Diskussion der genutzten Bilanzmethoden, die beispielsweise Ralf Ewert und Alfred Wagenhofer 2016 betrieben wird. Ein weiterer Schwerpunkt ist die Untersuchung der Finanzkennzahlen, wo deren Aussagekraft kritisch hinterfragt wird. Hier ist beispielsweise das Werk “Finanzkennzahlen und Unternehmensbewertung"" von Jochen Drukarczyk und Claudia Ossola-Haring aus dem Jahr 2017 zu nennen.
Der letzte große Schwerpunkt ist die Erstellung von Prognosen. Bei der Erstellung von Bilanzanalysen wird es immer wichtiger, nicht nur den Ist-Zustand zu analysieren, sondern auch fundierte Prognosen für die zukünftige Entwicklung des Unternehmens aufstellen zu können. Dies ist aktuell nur sehr schwer möglich. Dennoch arbeitet die Wissenschaft daran, in diesem Bereich neue Modelle und theoretische Grundlagen zu entwickeln, die helfen sollen, aussagekräftige Prognosen aufzustellen (Schult E, Brösel G, 2014). Zwei Beispiele solcher empirischen Untersuchungen sind “Die Prognose von Insolvenzen anhand einzelner Kennzahlen” von Günther Gebhardt und Financial Modeling and Valuation: A Practical Guide to Investment Banking and Private Equity” von Paul Pignataro.  
Das Thema Bilanzanalyse ist so komplex und relevant, dass neben diesen drei Forschungsschwerpunkten viele weitere Werke verfasst werden, die sich mit anderen Fragen und Aspekten der Bilanzanalyse beschäftigen. So wird in dieser Arbeit beispielsweise oftmals “Die Bilanzanalyse: Beurteilung von Abschlüssen nach HGB und IFRS” von Peter Küting zitiert, welches als Einführung in das Thema dient. 

6 Methoden der Bilanzanalyse
Eine Bilanzanalyse wird immer mit dem Ziel erstellt, die Informationen aus einem Jahresabschluss erkenntniszielorientiert aufzuarbeiten (Küting, 2015, S1). Die dabei genutzten Methoden unterscheiden sich bezüglich der Art und Weise, wie die verfügbaren Daten aufgearbeitet werden sollen und mit welchem Ziel die Analyse durchgeführt wird. Da Bilanzanalysen in so vielen verschiedenen Bereichen intensiv genutzt werden, existiert eine enorme Methodenvielfalt, die in dieser Arbeit keinesfalls vollständig abgebildet werden kann.
Bestimmte Methoden sind jedoch besonders etabliert und werden sehr häufig eingesetzt. Beinahe unverzichtbar ist die Analyse anhand von Kennzahlen. Kennzahlen sind hochverdichtete Marktgrößen, die aus anderen Zahlen (oftmals auch Kennzahlen) gebildet werden und komplexe Zusammenhänge in einer Zahl zusammenfassen können (Küting, 2015, S.15). Sie eignen sich somit hervorragend zur Abstraktion von Komplexität und können helfen, wichtige Zusammenhänge wie die Liquidität oder die Rentabilität eines Unternehmens schnell zu erfassen. Aus mehreren Kennzahlen entstehen Kennzahlensysteme mit einer größeren Aussagekraft. Ein besonders populäres Kennzahlensystem ist das DuPont-Kennzahlensystem, mit dem die Rentabilität eines Unternehmens untersucht wird.
Eine weitere wichtige Methode stellt der Vergleich dar. So wird bei der horizontalen Analyse die Bilanz eines Unternehmens aus mehreren aufeinander folgenden Jahren miteinander verglichen und so Veränderungen in der Leistungsfähigkeit des Unternehmens festgestellt. Bei der Benchmark Analyse werden hingegen die Bilanzen von konkurrierenden Unternehmen verglichen und so die Wettbewerbsfähigkeit der beiden Vergleichsfälle überprüft.

6.1 Grenzen und Möglichkeiten der Bilanzanalyse
Im Allgemeinen lässt sich feststellen, dass die Bilanzanalyse beim Erwerb von Unternehmensanteilen eine zentrale Rolle spielt, um das jeweilige Unternehmen zu überprüfen. Wie gut hat sich das Unternehmen in den vergangenen Jahren entwickelt? Wie verlässlich hat es seine selbst gesetzten Ziele erreicht und wie gut schneidet es im Vergleich zu anderen Unternehmen ab? All diese Fragen können mit einer Bilanzanalyse beantwortet werden.
Die dabei gewonnenen Erkenntnisse haben in ihrer Aussagekraft aber oftmals schwer einzuschätzende Grenzen. Ein zentraler Unsicherheitsfaktor, der jede Bilanz und damit auch jede ihrer Analysen stark beeinflusst, ist die Bilanzpolitik. Die Erstellung einer Bilanz wird durch das Handelsgesetzbuch (HGB) und bei international agierenden Unternehmen durch die International Financial Reporting Standards (IFRS) geregelt. Diese Regelwerke bieten jeder Unternehmensführung einen Handlungsspielraum, in dem diese eine eigene Bilanzpolitik durchsetzen und dadurch die zu veröffentlichende Bilanz beeinflussen kann (Küting, 2015, S. 76). Dies führt außerdem dazu, dass in den meistens Fällen nur jene Informationen in einer Bilanz veröffentlicht werden, die gesetzlich vorgeschrieben sind (ebd.).
Ein weiteres Problem ist die späte Veröffentlichung von Jahresabschlüssen. Meistens werden diese erst Monate nach dem Ende des Jahres veröffentlicht und sind daher bereits mit ihrer Veröffentlichung veraltet. Die zeitliche Diskrepanz spielt meistens keine große Rolle, kann jedoch im Falle einer Ausnahmesituation von Bedeutung sein.
Die größte Schwäche von Bilanzanalysen geht jedoch mit ihrer größten Stärke einher. Während die Bilanz beispielsweise durch die Nutzung von Kennzahlen komplexe Sachverhalte in einer einzelnen Zahl zusammenfasst und eindeutig quantifiziert, werden bei dieser Abstraktion viele nicht quantifizierbare und dennoch relevante Aspekte vernachlässigt. Werden nur die Zahlen einer Bilanz in Kennzahlen umgewandelt und miteinander verglichen, bleiben Faktoren wie die Qualität des Managements, die Marktstellung, das Image sowie das technische Know-how im Unternehmen außen vor (Küting, 2015, S.74).
Als letztes größeres Problem folgt in Deutschland das dominierende Vorsichtigkeitsprinzip. Während das Prinzip in der internationalen Bilanz eine geringere Bedeutung besitz, verstärkt es in Deutschland den Vergangenheitsbezug. Die feststehenden Faktoren der Vergangenheit haben durch das Prinzip einen deutlich höheren Stellenwert als mögliche Entwicklungen in der Zukunft (ebd.). Alle genannten vorgestellten Fehlerquellen verdeutlichen die Grenzen der Bilanzanalyse für Investoren. Egal wie ausführlich und gründlich sie durchgeführt wird. Sie kann niemals ein eindeutiges Ergebnis liefern, auf das sich ein Investor zweifellos verlassen kann. Dennoch liefert sie die besten Einblicke, die von außen in die finanzielle Situation eines Unternehmens möglich sind. Sie bleibt demnach das wertvollste Werkzeug, um Unternehmen aus finanzieller und betriebswirtschaftlicher Sicht so gut wie möglich einzuschätzen.

6.2 Methodischer Ansatz für die Bilanzanalyse der SAP SE
Beim methodischen Ansatz, der in dieser Arbeit gewählt worden ist, werden viele der zuvor beschriebenen Methoden miteinander in einer gemeinsamen Analyse verbunden. Auf diese Weise lassen sich viele der zuvor beschriebenen Schwierigkeiten ausgleichen. So wird in dieser Arbeit anfangs eine kurze qualitative Analyse durchgeführt, um erst danach im Rahmen der quantitativen Analyse mit Kennzahlen und Vergleichsmethoden zu arbeiten. Bei der qualitativen Methode wird die aktuelle Marktstellung der SAP SE veranschaulicht und festgestellt, welche Herausforderungen oder Schwierigkeiten es aktuell auf welche Art und Weise bewältigt.  
Erst danach wird in der typischen quantitativen Analyse begonnen, mit Kennzahlen und Vergleichsmethoden zu arbeiten. Im ersten Teil der quantitativen Analyse wird die finanzielle Gesundheit des Unternehmens überprüft. Dabei wird das Eigenkapital und die Schuldenlast analysiert und festgestellt, wie stabil das Unternehmen im finanziellen Bereich aufgestellt ist. Anschließend wird auf die Umsatzentwicklung eingegangen. Zum Vergleich wird an dieser Stelle die Umsatzentwicklung von SAPs größten Konkurrenten Salesforce herangezogen. 
Als drittes wird mithilfe des DuPont Kennzahlsystems die Rentabilität des Unternehmens untersucht. Danach wird eine Cash-Flow Analyse durchgeführt. Bei dieser Analyse wird vor allem die Liquidität des Unternehmens untersucht, um festzustellen, ob es dazu in der Lage ist, seine kurzfristigen Verbindlichkeiten auszugleichen und bei Bedarf ohne Probleme neue Investitionen tätigen kann (Timothy, 2012, S.1-3). Dafür wird das Cash-Flow Statement untersucht und die Kennzahlen zur Bewertung der Liquidität interpretiert. Zum Schluss werden die Aktien und ihre Dividenden angesehen. Mit Kennzahlen wie dem KGV wird deren Attraktivität für Anleger bewertet. SAP veröffentlicht jeweils einen Jahresabschluss nach dem HGB und einen gemäß dem IFSR-Standard, die beide zu unterschiedlichen Ergebnissen kommen. In dieser Arbeit werden die IFSR- Abschlüsse als Grundlage für die Bilanzanalyse genutzt.

7 Bilanzanalyse zum Jahresabschluss der SAP SE 2022 (IFSR)

7.1 Qualitative Analyse 
Die SAP SE ist das drittgrößte Softwareunternehmen weltweit und der Marktführer in der Entwicklung und dem Vertrieb von Softwarelösungen zur Abwicklung sämtlicher Geschäftsprozesse (Investopedia, 2020). Diese Stellung hat das Unternehmen im Verlauf der letzten Jahrzehnte gefestigt, wird in den letzten vier Jahren jedoch zunehmend durch schnell wachsende Konkurrenzunternehmen herausgefordert. Vor allem Oracle und Salesforce machen SAP Marktanteile streitig (Finanznachrichten, 2022). Teilweise wechseln Kunden ihren Anbieter, da ihnen die SAP-Lösungen zu kostspielig, undynamisch und weniger benutzerfreundlich sind. Dies trifft vor allem im Bereich des Customer-Relationship-Managements zu (Wirtschaftswoche, 2018). Eine wachsende Unzufriedenheit der Kunden zeigt sich auch im Annual Report nach dem “Form 20-F""4 aus dem Jahr 2022, bei der SAP nur einen Score von 3 erreicht aber bis zu 10 Punkte möglich sind (SAP Annual Report on Form 20-F, 2022, S.38).
Zugleich befinden sich alle Softwareunternehmen in einem großen Transformationsprozess, in dem sie ihre Dienste zunehmend im Rahmen eines Subskriptionmodells anbieten und die Nutzung verstärkt in die Cloud verlagern. Deser Wandel führt in der gesamten Branche zu einem hohen Investitionsbedarf, der sich auch in allen Bilanzen widerspiegelt.
Bei Investoren und auf dem Arbeitsmarkt hat SAP trotz der aktuellen Herausforderungen weiterhin einen exzellenten Ruf. Das gute Image zeigt sich unter anderem in den regelmäßig guten Arbeitgeberrankings (Arbeitgeber-ranking, n.d), sowie den ESG-Rankings, in denen das Unternehmen als besonders risikoarm und nachhaltig eingestuft wird (Sustanalytics, 2022). Investoren gehen demnach davon aus, dass die Unternehmensführung sinnvolle Ziele anstrebt und die eigens aufgestellten Anforderungen auch in den allermeisten Fällen erfüllt.

7.2 Analyse der finanziellen Stabilität
GEFEG hat bei seinen Überlegungen, Unternehmensanteile zu kaufen, keine spekulativen Absichten. Sollte ein Kauf stattfinden, so ist es das Ziel, diese Anteile auch langfristig zu halten. Dementsprechend wichtig ist die finanzielle Stabilität der SAP. Es sollte möglich sein, die Anteile zu halten, ohne mit erheblichen Schwierigkeiten des Unternehmens rechnen zu müssen, die schnell zu massiven Kursverlusten führen können. In dieser Hinsicht ist vor allem die Eigenkapitalquote wichtig. Gute Quoten liegen je nach Branche bei mindestens 20- 30%. Je größer der Anteil des Eigenkapitals am Gesamtkapital ist, desto einfacher kann das Unternehmen in Krisenzeiten Fremdkapital/Schulden zu günstigen Konditionen aufnehmen und die Krisenlage auf diese Art und Weise komfortabel überstehen. 
Tab. 1: Tabellarische Darstellung des Eigenkapitals
Jahr 	Eigenkapital (in Mio €) 	Eigenkapitalquote (in %) 
2019 	30.822 	51,18 
2020 	29.928 	51,16 
2021 	41.523 	58,34  
2022 	42.848 	59,37 
Quellen des jeweiligen Eigenkapitals sind die “Annual Reports on Form 20-F"" der SAP SE aus den Jahren 2020,2021, und 20227 
Die SAP SE zeichnet sich demnach durch eine hervorragende Eigenkapitalquote aus. Selbst während einer Transformationsphase, in der das Unternehmen nach eigenen Aussagen viel Kapital in den Aufbau des Cloud-Geschäfts steckt, sowie der Corona-Pandemie mit all ihren wirtschaftlichen Unsicherheiten hat das Unternehmen nicht nur die Quote auf einem stabilen Niveau gehalten, sondern zugleich das Eigenkapital massiv erhöhen können. Im Jahr 2021 hat das Unternehmen sein Eigenkapital um 28 % gesteigert. Zudem ist im gleichen Jahr der Anteil des Eigenkapitals um 7 Prozentpunkte gestiegen. Wird die Eigenkapitalquote des Unternehmens im Verlauf der letzten vier Jahre betrachtet, macht die SAP SE demnach in finanzieller Hinsicht einen sehr stabilen und erfolgreichen Eindruck.

7.3 Umsatz- und Gewinnentwicklung
SAP konnte in den vergangenen Jahren kontinuierlich seine Wachstumsprognosen einhalten und seinen Umsatz in den letzten fünf Jahren um durchschnittlich 3,9 % steigern. Es kann davon ausgegangen werden, dass SAP diesen antizyklischen sowie stabilen Wachstumskurs auch in Zukunft einhalten kann. Für sich allein betrachtet ist das Wachstum im Umsatz eine Erfolgsstory. Im Vergleich zum aufsteigenden Konkurrenten Salesforce verdüstert sich hingegen die Prognose. Salesforce macht SAP mit seinen eigenen CRM-Lösungen große und wichtige Marktanteile streitig und holt im Umsatz nicht nur auf, sondern wird SAP in diesem Jahr im Umsatz wahrscheinlich einholen oder sogar überholen.  Allein 2022 verzeichnete Salesforce ein größeres Umsatzwachstum als SAP in den letzten fünf Jahren zusammengenommen. Es hat den Anschein, als dass SAP seine bisher unangefochtene Position im Bereich der Unternehmenssoftware einbüßen wird. Es bleibt fürs Erste schwer abzusehen, mit welchen negativen Auswirkungen der Verlust dieser Stellung in Zukunft einhergehen kann.
Abb. 1: SAP's Umsatz von 2001-2022 (€)                 Abb. 2: Salesforce Umsatz von 2010-2023 ($) 
           Quelle: Lionel Sujay Vailshery auf Statista, 2023            Quelle: Lionel Sujay Vailshery auf Statista, 2023 
Umsatz allein zeichnet jedoch keinen unternehmerischen Erfolg aus. Diesbezüglich ist vor allem der Gewinn wichtig, den ein Unternehmen erzielt. In diesem Bereich ist SAP seinem Konkurrenten noch weit voraus. Während SAP verlässlich einen Gewinn von mindestens drei Milliarden (vor Steuern) erwirtschaftet, sind Salesforce jährliche Reingewinne unberechenbar und teilweise kaum vorhanden. Während Salesforce ausschließlich auf Wachstum und eine Steigerung des Unternehmenswertes setzt und dafür mehr Marktanteile gewinnen möchte, zielt SAP’s Unternehmensstrategie auch auf einen Gewinn ab, der teilweise an die Aktionäre ausgeschüttet wird. Hier zeigt sich die Stärke und Qualität, die SAP Salesforce zum aktuellen Zeitpunkt noch voraushat.
Abb. 3: SAP's Reingewinn von 2006-2022(€)     Abb. 4: Salesforce Reingewinn von 2015-2023($)
      Quelle: Lionel Sujay Vailshery auf Statista, 2023        Quelle: Lionel Sujay Vailshery auf Statista, 2023 

7.4 Du Pont Kennzahlsystem zur Feststellung der Rentabilität 
In den beiden Abschnitten zuvor wurde der Gewinn, Umsatz sowie das Eigenkapital bereits untersucht. Die Erkenntnisse aus diesen Abschnitten fließen in diesen Teil der Arbeit ein, um die Rentabilität der SAP SE zu untersuchen. Das Ergebnis des DuPont-Kennzahlensystems ist der ROI, eine Kennzahl, die zeigt, wie gut ein Unternehmen seine ihm zur Verfügung stehenden Mittel nutzt, um einen Gewinn zu generieren. Je höher der Wert, desto effizienter schöpft das Unternehmen seine Möglichkeiten aus.
Abb. 5: DuPont-Kennzahlsystem basierend auf dem SAP Annual Report on Form 20-F 2022: 
 Quelle: eigene Darstellung
Der ROI-Wert wird mithilfe weiterer Kennzahlen berechnet. Hervorzuheben sind dabei die Umsatzrendite und der Kapitalumschlag. Die Umsatzrendite gibt an, wie effizient der Umsatz eines Unternehmens in einen Gewinn umgewandelt wird. Im Jahr 2022 kam SAP auf eine Umsatzrendite von 5,5 %. Im Vergleich zu anderen deutschen Unternehmen ist diese Rendite Mittelmaß (Rudnicka, 2022). Anders sieht es beim Kapitalumschlag aus. Diese Kennzahl gibt an, wie effizient das eingesetzte Kapital genutzt wird, um Umsatz zu generieren. Mit 0,42 hat SAP einen sehr niedrigen Wert, der für eine schlechte ineffiziente Nutzung des eingesetzten Kapitals spricht. 
Erklären lässt sich dieses schlechte Ergebnis vermutlich durch einen hohen “Goodwill”, der für immaterielle Werte steht. SAP beziffert diesen Wert auf 33.106 Mio. € des Anlagevermögens (SAP Annual Report, 2023, S.215) , das insgesamt mit 43.402 € bewertet wird. Im Gegensatz zu Unternehmen mit Maschinen, Rohstoffen und dem Vertrieb von materiellen Waren vertreibt SAP seine Software an Kunden. Der tatsächliche Wert dieser Software lässt sich im Vergleich zu Maschinen und Waren schlechter ermitteln. Je nachdem welche Bewertungskriterien genutzt werden, um den finanziellen Mehrwert ihres Know-Hows, ihrer Software und ihres Images zu messen, kann der Wert “Goodwill” sich stark von Unternehmen zu Unternehmen ändern. 
SAP begründet den hohen Goodwill-Wert mit Acquisitions, die das Unternehmen in den vergangenen zwei Jahren getätigt hat (Jahresabschluss von SAP, 2022, S.51). Das Know-How und die Synergieeffekte, die sich das Unternehmen dadurch verspricht, fließend bereits in die Bewertung mit ein, werden sich aber erst langfristig auch in einem steigenden Umsatz oder geringen operativen Kosten widerspiegeln. Die ROI-Werte sind jedoch mit 2,2 % im Jahr 2021 und 2,41 % im Jahr 2020 auch für die vergangenen Jahre schlecht . Die SAP-Jahresbilanzen zeichnen sich demnach durch einen schlechten ROI-Wert aus, unabhängig von getätigten Akquisitionen. Bei diesem Teil der Bilanzanalyse erzielt SAP demnach kein gutes Ergebnis.

7.5 Cashflow-Analyse 
Bei den bisherigen Methoden wurden Informationen aus der Jahresbilanz und dem Gewinn- und Verlustkonto (GuV) als Grundlage genutzt. Nachdem diese beiden zentralen Teile jedes Jahresabschlusses bereits untersucht wurden, folgt nun zum Schluss die Analyse des Cash-Flow Statements. Die Eigenkapitalquote ist bereits ein erster Indikator für die finanzielle Stabilität eines Unternehmens. Die Kennzahl stellt aber nur fest, wie viel Eigenkapital verhältnismäßig zur Verfügung steht. Offen bleibt, wie das Kapital eingesetzt wird. Mit der Cash-Flow-Analyse lässt sich diese offene Frage beantworten. Im Idealfall kann ein Unternehmen all seine Verbindlichkeiten an Lieferanten und Kreditgeber fristgerecht begleichen und hat zusätzliche Mittel für Investitionen zur Verfügung, ohne in jedem Fall Fremdkapital aufnehmen zu müssen. Gleichzeitig sollten nicht zu viele liquide Mittel zur Verfügung stehen, die nicht eingesetzt werden und somit keine Rendite generieren können. Das Cash-Flow Statement aus dem Jahresabschluss der SAP beinhaltet neben dem Jahr 2022 auch die zwei vorangegangenen Jahre als Vergleichswerte. Wie gewohnt ist das Cash-Flow Statement in die drei Unterbereich für operative, investierende und finanzielle Aktivitäten unterteilt.
Tab. 2: Zusammenfassung des Cashflows der SAP SE (in Mio. €) 
Aktivität 	2022 	2021 	2020 
Operative Aktivitäten 	5.647 	6.223 	7.194 
Investitionsaktivitäten 	667 	-3.063 	-2.986 
Finanzielle Aktivitäten 	-6.337 	-56 	-3.997 
Quelle: Eine vollständige Abbildung des Cashflow-Statements liegt im Abbildungsverzeichnis Nr. 1 vor. 
Im ersten Unterpunkt, dem operativen Cashflow, ist in den letzten drei Jahren durchweg ein positives Ergebnis erzielt worden. Demnach schafft es SAP zumindest im operativen Geschäft mehr Geld einzunehmen als auszugeben. Sollte dies nicht der Fall sein, wäre von einem Kauf der Unternehmensanteile unbedingt abzuraten. Das Ergebnis ist in den letzten Jahren aber zunehmend gesunken. Generierte das Unternehmen 2022 noch einen operativen Cashflow von 7.194 Mio € liegt dieser 2022 nur noch bei 5.647 Mio. € (Siehe Abbildung Nr.1).  Auffällig ist eine kontinuierliche Steigerung des genutzten Vermögens für das aktive Geschäft.  Wurden dafür 2020 nur 651 Mio. € aufgewendet, sind es 2022 bereits 1.312 Mio. € (ebd.). Diese Steigerung hat einen großen Anteil an der Verringerung der zur Verfügung stehenden Mittel im operativen Geschäft und zeugt von einer geringer werdenden Effizienz. 
Bei den investierenden Aktivitäten gab es 2022 einen Cashflow von 667 Mio. €, 2021 waren es –3.063 und –2.986 Mio. € im Jahr 2020 (ebd.). Ausschlaggebend für das große Minus sind die getätigten und bereits erwähnten Akquisitionen in den letzten zwei Jahren. 2022 wurden keine Akquisitionen durchgeführt und damit eher ein positiver Cashflow generiert. In allen drei Jahren wurden rund 800 Mio. € in neue Ausstattung und Einrichtungen investiert. Im Allgemeinen kann im positiven festgehalten werden, dass SAP einen gewichtigen Teil seiner Mittel in jedem Jahr für Investitionen ausgibt und diese Ausgaben mindestens den Wertverlust ausgleichen, der durch Abschreibungen verursacht wird. Das Unternehmen reinvestiert also einen gewichtigen Teil seiner liquiden Mittel in die Zukunftsfähigkeit - ein gutes Zeichen für jeden Investor.
Im Jahr 2022 verzeichnet SAP einen besonders starken Verlust von liquiden Mitteln bei den finanziellen Aktivitäten. Während das Unternehmen in den letzten zwei Jahren jeweils über 1.900 Mio. € aufgenommen hat, hat es 2022 beinahe vollständig auf die Aufnahme von neuem Fremdkapital verzichtet und zugleich Verbindlichkeiten beglichen. Des Weiteren hat es 1.500 Mio. € ausgegeben, um eigene Anteile vom Markt zurückzukaufen. Es hat höchstwahrscheinlich Mitte 2022 einen starken Kursverfall aufgrund des Ukraine Krieges ausgenutzt, um zu günstigen Konditionen die eigenen Anteile zu erwerben. Der Aktienwert hat sich seitdem wieder erholt. Der große Verlust an liquiden Mitteln im Finanzbereich ist demnach gut begründet. Es wurden zum richtigen Zeitpunkt eigene Anteile zurückgekauft und außerdem zu einer günstigen Zeit Schulden beglichen, da 2022 keine größeren Akquisitionen durchgeführt wurden. Die großen Ausgaben lassen sich demnach gut erklären.  
Das Cashflow Statement macht einen durchwachsenen Eindruck. Vor allem die sinkende Effizienz im operativen Geschäft ist besorgniserregend. Auf der anderen Seite ist das operative Geschäft immer noch ein Erfolg, Investments in die Zukunft des Unternehmens werden weiterhin getätigt und ein nachvollziehbares Zurückzahlen von Schulden und das Aufkaufen eigener Aktien im Jahr 2022 zeugen auch von einer strategisch und langfristig denkenden Unternehmensführung.
Zudem verfügt das Unternehmen damit wie bereits in den vergangenen Jahren über ein gleichbleibendes Maß an zur Verfügung stehenden liquiden Mitteln. Nachdem es 2021 bereits 8.898 Mio. € am Ende des Jahres waren, verfügte SAP auch 2022 über 9.008 Mio. €. Auf der Grundlage dieser Werte lassen sich auf die Liquidität des ersten und zweiten Grades berechnen.  Im Jahr 2022 besitzt SAP einen Liquiditätsgrad ersten Grades von 51 % und einen Liquiditätsgrad zweiten Grades von 87,3 %. Im letzten Jahr waren es noch jeweils 55,1 % und 94,5 %. Bezüglich des ersten Grades werden alle Prozentwerte über 50 % und unter 70 % als gut bewertet (Welt der BWL, n.d.). Beim zweiten Grad ist ein Wert von 100 % ideal (ebd.). Beide Prozentwerte sind 2022 gesunken – die Kennzahl zweiten Grades hat sich sogar recht weit von den normalerweise angestrebten 100 % entfernt. Auch in diesem Bereich findet die Verschlechterung aber noch in einem moderaten Ausmaß statt. Vor allem angesichts der hohen Eigenkapitalquote und trotz der Ausnahmesituation durch den Ukraine Krieg wird das Unternehmen im Falle eines Notfalls schnell neues Kapital beschaffen können.

7.6 Bewertung der Aktie 
Im Rahmen dieser Analyse wird der Aktienwert am Tag des Jahresabschlusses zur Berechnung von Kennzahlen genutzt. Dieser betrug am 31.12.2022 genau 96,32 € (Börse.de, 2023). Im Verhältnis zum Jahr 2012 mit einem Jahresabschlusskurs von 60,79 € (ebd.) ist der Kurs in jedem Jahr um durchschnittlich 6,3 % gestiegen. Im letzten Jahr gab es einen erheblichen Kursverlust, der mit einem schlechten Zwischenergebnis und einer düsteren Prognose aufgrund des Ukraine-Krieges einherging (SAP Quarterly Statement Q2 2022 , 2022, Seite 5). Von diesem Kursverfall hat sich die Aktie aber wieder erholt und steht heute, am 26.03.2023 bei 114 €. Die wohl wichtigste Kennzahl in Bezug auf eine Aktie ist die KGV (Kurs-Gewinn-Verhältnis), die angibt, wie viele Jahre bei gleichbleibendem Unternehmensgewinn benötigt werden, bis ein Anleger den Wert erhält, den er selbst in die Aktie investiert hat.
Tab. 3: Tabellarische Zusammenfassung des Kurs-Gewinn-Verhältnisses der SAP-Aktie 
Jahr 	2019 	2020 	2021 	2022 
Gewinn je Aktie 	2,78 	4,35 	4,45 	1,95 
KGV (Jahresendkurs) 	43,26 	24,63 	28,04 	49,38 
Quelle: eigene Darstellung, Informationen zum Gewinn, Anzahl und Wert Aktien wurden den Jahresabschlüssen aus den Jahren 2020 und 2022 entnommen.  
Bei dieser wichtigen Kennzahl schneidet SAP im Verhältnis zu anderen deutschen Großkonzernen eher schlecht ab, die alle KGV-Werte rund um die Zahl 10 besitzen (Handelsblatt, 2023). Vor allem das letzte Jahr 2022 zeichnet sich durch den Ukraine-Krieg mit einem sehr schlechten Ergebnis aus. Es könnte eingewendet werden, dass die KGV-Kennzahl auch ihre Schwächen hat. So berücksichtigt sie nicht das potenzielle Wachstum des Unternehmens, durch das der Wert einer Aktie langfristig enorm steigen kann. So besteht beispielsweise nach der Tesla Aktie eine große Nachfrage, auch wenn je Aktie im vergangenen Jahr nur 1,05 $ Gewinn generiert wurde und so ein KGV-Wert von 227 zustande kam. Anleger schätzen die Innovationskraft und zukünftige Leistungsfähigkeit des Unternehmens so hoch ein, dass die Aktien von Tesla trotz dieser schlechten Werte gerne gehalten oder gekauft werden. SAP ist aber kein dynamisches Unternehmen mit der Bestrebung, neue Märkte zu erobern. Stattdessen ist es eher darum bemüht, seinen Umsatz langsam auszubauen, seine Marktanteile zu verteidigen und Dividenden an seine Aktionäre auszuschütten. Für ein solches etabliertes Unternehmen ist ein so unterdurchschnittlicher KGV-Wert kein gutes Zeichen.  

8 Handlungsempfehlungen an die GEFEG mbH
Die Ergebnisse der Bilanzanalyse der SAP SE sind zwiespältig. Sie zeigen ein langfristig erfolgreiches Unternehmen mit stabilen Finanzen, einem soliden Wachstum und verlässlichen Gewinnen, die an die Aktionäre ausgeschüttet werden. Auch macht die Unternehmensführung mit dem Blick auf die Finanzen einen kompetenten Eindruck.  Zugleich hat das Unternehmen in den letzten zwei Jahren mit Problemen zu kämpfen, bei denen zum aktuellen Zeitpunkt unklar ist, inwiefern diese überwunden werden können. Gegen die erstarkende Konkurrenz hat SAP bisher keine erfolgreiche Strategie gefunden und muss erst noch zeigen, dass es sich von der Krise im letzten Jahr erholen kann. 
Der aktuell schwächere Kurs, der immer noch hinter dem Allzeithoch aus dem Jahr 2020 oder dem höchsten Kurs aus dem Jahr 2021 liegt, könnte ein passender Zeitpunkt für einen Einstieg sein. Es ist jedoch fraglich ob und inwiefern das Unternehmen an seine alten Erfolge in der Zukunft anknüpfen kann. Vor allem im Hinblick auf den schlechten ROI und KGV-Wert wirkt ein Einstieg in das Unternehmen nicht so attraktiv wie andere Investmentmöglichkeiten, die hier bessere Zahlen vorzuweisen haben.  
Hinzu kommt die finanzielle Situation der GEFEG mbH. Ein Unternehmen mit einer Eigenkapitalquote von unter 30 % ist in keiner Position in der Investitionen in andere Unternehmen besonders attraktiv erscheinen. Und SAP macht in dieser Analyse keinen so attraktiven Eindruck, dass in dieser Situation eine Investition in Unternehmensanteile zu empfehlen sind. Stattdessen sollte GEFEG sein Kapital wohl eher in das eigene Unternehmen investieren oder Verbindlichkeiten begleichen, um die Eigenkapitalquote zu erhöhen. Aus diesen Gründen wird es im Rahmen dieser Arbeit der GEFEG mbH nicht empfohlen, Anteile der börsennotierten SAP SE zu erwerben. 

9 Fazit
Die im Rahmen dieser Arbeit durchgeführte Bilanzanalyse zeichnet ein durchwachsenes Bild der SAP SE. Das Unternehmen hat aus gutem Grund auf dem deutschen Markt weiterhin eine große Strahlkraft und wird als größtes Softwareunternehmen hoch angesehen. Wie die Analyse zeigt, ist die Reputation in vielerlei Hinsicht auch gut begründet. Gleichzeitig hat sich die Ausgangssituation für das Unternehmen in den vergangenen Jahren zusehends verschlechtert. Für diese Entwicklung gibt es diverse Anzeichen wie die sinkende Effizienz im operativen Geschäft, eine abfallende Liquidität, ein Wachstum, das mit dem der Konkurrenz nicht mithalten kann und schwache Ergebn"
Textoptimierung für SEO;""
Vorstellung von Anglers Paradise;"4 Einleitung
Angeln, ein Wassersport mit einer breiten Anhängerschaft aller Altersgruppen, offenbart ein besonderes Vergnügen für Menschen im fortgeschrittenen Alter. Die friedliche und ruhige Atmosphäre am Wasser kann eine heilende Wirkung auf den Geist und Körper haben, indem es den Stress reduziert. Viele Studien legen nahe, dass das Angeln bei älteren Erwachsenen mit einer Reduktion von Depressionen und Angstzuständen und einer Steigerung der kognitiven Funktionen und des allgemeinen Wohlbefindens verbunden ist (Griffiths et al., 2017). Die Synergie zwischen körperlicher Aktivität und geistiger Entspannung beim Angeln führt zu einer gesünderen körperlichen und geistigen Verfassung.
Eine tiefe Verbindung zur Natur und das Gefühl der Selbstständigkeit und des Erfolgs, wenn ein Fisch gefangen wird, sind weitere Aspekte, die Angeln für ältere Erwachsene besonders attraktiv machen. Es bietet auch eine Gelegenheit, soziale Bindungen zu stärken, indem es mit anderen geteilt wird, ob mit Familienmitgliedern, Freunden oder Gleichgesinnten. Das gemeinsame Erlebnis des Angelns kann langanhaltende Erinnerungen und eine noch tiefere Verbundenheit hervorrufen.
Anglers Paradise soll Anglern dabei helfen, ihr Erlebnis zu optimieren und noch erfolgreicher zu gestalten. Mit der fortschreitenden Technologie bieten digitale Werkzeuge und Tools in der Angelapp wertvolle Informationen über Angelplätze, Wettervorhersagen und sogar Fischarten und Köder an. Die App ist auch eine hervorragende Möglichkeit, das Angelerlebnis zu dokumentieren und zu teilen, um Erinnerungen festzuhalten und soziale Bindungen zu stärken.
Im Allgemeinen kann das Angeln Menschen helfen, körperliche Aktivität und mentale Entspannung miteinander zu kombinieren und so zu einem gesünderen und glücklicheren Lebensstil beitragen. Anglers Paradise soll helfen, das Angelerlebnis noch besser zu gestalten und den Nutzern eine optimale Erfahrung am Wasser zu bieten. Mit all diesen Vorteilen und den zusätzlichen digitalen Ressourcen wird das Angeln zu einem noch unvergesslicheren Erlebnis, das Menschen jeden Alters und jeder Erfahrungsstufe miteinander verbindet.
5 Forschungstand: Umfeld- und interne Analysen
5.1. Marktanalyse
Der Markt für Angelequipment in Deutschland mag zwar stagnieren, aber es gibt immer noch ein hohes Potenzial für Wachstum, da etwa 6,46 Millionen Menschen mindestens einmal im Jahr angeln gehen. Davon sind etwa 3,3 Millionen „Oftangler“, die regelmäßig Angelzubehör benötigen, um ihrer Leidenschaft nachzugehen (Arlinghaus, 2004). Der Markt für Angelzubehör wird auf etwa 119,8 Millionen Euro geschätzt, wobei ein Anstieg von 1,83% jährlich erwartet wird (Statista, 2022).
In Deutschland gibt es derzeit 676 aktive Fischereien, darunter 346 Hauptbetriebe sowie 330 Neben- und Zuerwerbsbetriebe (Arlinghaus, 2004). Diese Fischereien spielen eine wichtige Rolle bei der Versorgung der Bevölkerung mit Fischprodukten. Angelvereine und -verbände besitzen fischereiliche Rechte auf etwa 270.000 Hektar Gewässer in Deutschland und bieten Anglern auch Fischereierlaubnisscheine an. Diese Vereine und Verbände bieten nicht nur den Zugang zu Gewässern, sondern fördern auch die Gemeinschaft und das soziale Netzwerk unter Anglern.
Darüber hinaus bietet der Markt für Angelzubehör auch ein hohes Potenzial für Innovationen und neue Technologien. Die Verwendung von High-Tech-Geräten wie Fischfindern und GPS-Systemen hat das Angelerlebnis deutlich verbessert und die Fangquote erhöht. Deswegen sollten Unternehmen, die in diesem Bereich tätig sind, sich auf die Bedürfnisse von Anglern konzentrieren, um davon profitieren zu können. 
Zusammenfassend bietet der Markt fürs Angeln als Wassersport in Deutschland ein großes Potenzial für Wachstum und Innovationen. Geschäfte sollten beachten, dass der Markt begrenzt ist und sich an den Bedürfnissen von Anglern und Angelvereinen und -verbänden orientiert. Außerdem liefert die Zusammenarbeit mit Fischereien bzw. Angelzubehöranbietern einen großen Beitrag, die Nachfrage nach Angelzubehör und -technologie zu steigern und daher den Markt weiterzuentwickeln.











5.2 SWOT-Analyse

Abb. 1: SWOT-Analyse von Anglers Paradise
 
Quelle: Eigene Darstellung
Stärken
Als Start-up hat das zukünftige Unternehmen dank seiner minimalen Größe eine flache Hierarchie und schlanke Prozesse, die eine große Rolle bei der Entwicklung und Umsetzung von Innovationen spielen. Außerdem ist die Idee der App einzigartig, die Fischer, Angelverein und Angler zusammenbringt. Das dient dazu, dass sich das Unternehmen leicht von anderen Konkurrenten aus demselben Marktsegmenten abheben kann.
Schwächen
Ein kleines Budget gehört zu den typischsten Eigenschaften eines Start-ups. Daher kann es dem Unternehmen schwerfallen, auf plötzliche Entwicklungen und mögliche Herausforderungen pünktlich und ordentlich zu reagieren. Des Weiteren verfügt ein Start-up am Anfang meist über ein kleines Netzwerk, was den Lösungsraum für die vorgenannten Probleme weiter einschränken könnte.
Chancen
Ein stagnierender aber langsam wachsender Markt könnte das ideale Umfeld für ein Start-up mit einzigartigen Produkten bzw. Dienstleistungen sein. Zusätzlich minimiert das Fehlen von Wettbewerbern auf nationaler bzw. internationaler Ebene die Möglichkeit, dass der Markt von einem finanziell stärkeren Konkurrenten übernommen wird. Diese beiden Faktoren bieten dem Unternehmen eine Chance, schnell Marktanteile zu gewinnen und die Aufmerksamkeit von Investoren auf sich zu ziehen.
Risiken
Das neue Unternehmen könnte jedoch auf lokale Konkurrenten treffen, z. B. auf kleine oder mittlere regionale Ausrüster oder Fischereibetriebe, die bereits einen festen Kundenstamm haben. Dies kann zu weiteren Schwierigkeiten führen, wenn das Unternehmen erst in den Markt eintritt.
SWOT-Strategien:
Abb. 2: SWOT-Strategien
 
Quelle: Eigene Darstellung

SO-Strategie: Erstellung zugeschnittener Produktempfehlungen
Mit der sozialen Plattform sind die Angelenthusiasten gut miteinander verbunden. Die von Nutzern geteilten Informationen lassen sich verwenden, um verbesserte Produktempfehlungen zu generieren. Somit lassen sich gleichzeitig die internen Prozesse des Unternehmens weiter optimieren und die Customer-Pain-Points reduzieren.


ST-Strategie: Vernetzung mit Angelverbänden und -vereinen auf regionaler Ebene
Die Zusammenarbeit mit den oben genannten Organisationen dient dazu, dass Partner, in diesem Fall die betroffenen Vereine und Verbände, eine größere Exposition für sich gewinnen können. Gleichzeitig erhält das Unternehmen die Lokalitäten und den Zugang zu deren Ressourcen.

WO-Strategie: Partnerschaften mit Angelzubehöranbietern bzw. perspektivisch mit Reiseanbietern
Aus der aktuellen Stagnation des Marktes für Angelzubehör lässt sich ein Mangel an Innovationen ableiten. Daher besteht die Hoffnung, dass das Unternehmen mit solchen Partnerschaften dem Markt einen Push geben und simultan sein kleines Netzwerk expandieren könnte.

WT-Strategie: Vermeidung direkter Konflikte mit potenziellen Partnern
Da es regional mehrere Konkurrenten mit festem Kundenstamm gibt, sollte das Unternehmen möglichst nicht in direkte Konflikte gegen sie treten. Im Gegenteil sind möglichst viele Partnerschaften zu etablieren, indem die letzten 2 Strategien angewandt werden. Außerdem ist es für das Unternehmen von Vorteil, in der Szene aktiv zu sein, z. B. durch die Organisation von Veranstaltungen und die Teilnahme an Tech-Messen, um mit den Entwicklungen in der Branche Schritt halten zu können.









6. Methodik: Prozessmodell nach SCHALLMO
Abb. 3: Prozess zur Geschäftsmodellentwicklung von Anglers Paradise
 
Quelle: Eigene Darstellung
Für diese Fallstudie wurde der Geschäftsmodellentwicklungsprozess nach SCHALLMO angewendet. Er besteht aus 5 Phasen: Initiierung, Konzeptualisierung, Konkretisierung, Prototypentwicklung und Implementierung & Test.

Initiierung
In dieser Phase wurden die Ergebnisse der Markt- und SWOT-Analyse gesammelt und ausgewertet. Ein Brainstorming-Prozess wurde durchgeführt, um Ideen für das Geschäftsmodell zu sammeln. Nachdem das Potenzial des Angelmarktes Deutschlands bzw. Europas mithilfe der gesammelten Daten der Marktanalyse ermittelt wurde, wurde die Entscheidung getroffen, eine Dienstleistung bzw. ein Produkt in diesem Marktsegmenten zu schaffen.
Konzeptualisierung
Anschließend wurde das Geschäftsmodell mithilfe des Business Model Canvas entworfen. Es wurden die Schlüsselpartner, Schlüsselaktivitäten, Schlüsselressourcen, Wertangebote, Kundenbeziehungen, Kundenkanäle, Kundensegmente, Kostenstruktur und Einnahmequellen definiert:
Tab. 1: Business Model Canvas von Anglers Paradise
 Quelle: Eigene Darstellung

Die obige Tabelle beschreibt das Geschäftsmodell, das auf der Grundlage der SWOT-Strategien entwickelt wurde. Die rot markierten Punkte des Geschäftsmodells entsprechen einzelnen Teilen, die zunächst wegen der Beschränkungen des Finanzierungsplans noch nicht realisiert werden konnten. 
Konkretisierung
Des Weiteren wurde das Geschäftsmodell mithilfe geeigneter Geschäftskonzepte aus den 55 Geschäftsmustern konkretisiert. Für das obige Geschäftsmodell wurden die folgenden Strategien/Muster verwendet:







Abb. 4: Angewandte Geschäftspatterns von Anglers Paradise
 
Quelle: Eigene Darstellung

Das Pattern „Customer Loyalty“ wird genutzt, um die Kundenbasis des Unternehmens mittels besonderer Vorteile und Incentivierung zu halten und zu expandieren. Diese können an die Kunden in Form einer Einladung zu speziellen Veranstaltungen bzw. Ausflügen oder Sonderrabatten weitergegeben werden. Ein weiteres Muster ist „E-Commerce“, weil fast alle Einnahmequellen des Unternehmens aus In-App-Käufen stammen. Als Nächstes folgt das Muster ""Open Business Model"", da das Eingehen neuer Partnerschaften für die Expansion des ursprünglich kleinen Netzwerks unerlässlich ist. Daran schließt sich das Muster „Two-sided Market“. Die Plattform soll sowohl Einzelpersonen als auch Anbietern dienen.
Somit werden auch die Schlüsselpartner als eine eigene Kundengruppe betrachtet. Schließlich wird ""Subscription"" verwendet, um die Vereine und Fischer an unsere Plattform zu binden. Mit dem kontinuierlichen Verkauf ihrer Tages- und Jahreskarten erzielen sie über die Plattform regelmäßig Einnahmen. Dafür müssen sie jedoch eine Subscription für die Nutzung der App abschließen.

Prototypentwicklung
In dieser vorletzten Phase wurde ein Liquiditätsplan auf Basis der Marktanalyse erarbeitet. Gleichzeitig geht es auch darum, die App auf die Bedürfnisse und Erwartungen der Nutzer auszurichten, indem besonderer Wert auf die Nutzerzentrizität gelegt wird. Mithilfe von FIGMA kann ein interaktiver Prototyp erstellt werden, der es ermöglicht, das User Interface (UI) und die User Experience (UX) zu testen und zu optimieren, bevor die eigentliche Implementierung beginnt.
Implementierung & Test
In der letzten Phase des Prozesses wurde auf der Grundlage des zuvor getesteten Prototyps ein detaillierter Finanzierungsplan erstellt. Anschließend wird ein Minimum-Viable-Product auf den Markt gebracht und entsprechend der Kundenreaktion und -feedbacks das Produkt bzw. das Geschäftsmodell angepasst.














7 Nutzergruppenidentifikation mit der AEIOU-Methode
Um ein besseres Verständnis im App-Designprozess für die Nutzergruppen zu bekommen, ist es für das Start-Up Anglers Paradise essenziell ihre zukünftigen Nutzer zu verstehen. Hierzu wurde die AEIOU-Methode verwendet um den Nutzer in einen direkten Kontext mit seiner Umgebung, seinen Aktivitäten und seinen vorhandenen Devices zu setzen. Dabei bedient sich die Methode einzelnen Kategorien die besonders als Start-Up dabei helfen, strukturierte Beobachtungen der Nutzergruppen vorzunehmen und neue Erkenntnisse zu gewinnen. Das AEIOU-Framework ist besonders unkompliziert und leicht adaptierbar da die einzelnen Kategorien an den individuellen Beobachtungsfall angepasst und verändert werden können. Wichtig zu beachten ist dabei nur, dass die einzelnen Kategorien in einem starken Bezug zueinanderstehen sollten und miteinander verknüpft werden. Anglers Paradise hat sich deshalb bei seiner Beobachtung und Auswertung von Nutzerumfragen zu dem Nutzerverhalten von Angelsportbetreibenden an Kategorien und Fragestellungen in der nachfolgenden Tabelle (Tab.2) orientiert.

Activities	
Welche Aktivitäten führen die Nutzer aus?
Environment	Wie ist das Umfeld charakterisiert?
In welcher Lebenssituation stehen die Nutzer?
Interaction	Wie interagieren die Nutzer mit Unternehmen & anderen Nutzern?
Wo interagieren die Nutzer, mit welchen Systemen?
Objects	
Welche Objekte/ Devices verwenden die Nutzer?
Users	Wer sind die Nutzer?
Welche Eigenheiten haben die Nutzer?
Quelle: Eigene Darstellung 

Zur Beantwortung der Fragestellungen, wurde der von Statista, mit dem Thema „Zielgruppe: Jäger: innen & Angler: innen in Deutschland“ Statista (10/2022), Global Consumer Insights Report verwendet. Dieser bot Anglers Paradise die Möglichkeit, zu Erkennen welche Kerncharakteristiken die potenziellen Zielgruppen aufweisen. So konnten aus dem Report, der auf einer Umfrage mit durchschnittlich 30.000 Teilnehmern beruht, sowohl demografische Eigenschaften der Konsumenten, sowie deren Lifestyle und Einstellungen herausgefiltert werden und in das AEIOU-Framework übernommen werden. 

Dabei ergab die Umfrage, das Angelsportbetreibende in Deutschland, neben der Outdooraktivität Angeln, meist noch andere Outdooraktivitäten bevorzugen. So gaben 58 % der Zielgruppen an ebenfalls an Aktivitäten rund um „Heim & Garten“ interessiert zu sein, sowie 54 % der Befragten, reisen als weiteres Hobby angaben. Ebenso wandern, sahen 50 % der Teilnehmenden als Hobby an. So ergeben sich für Anglers Paradise bereits erste Rückschlüsse darauf, wie die Zielgruppe in ihrer Freizeit agiert und welche Interessen auch in Zukunft möglicherweise, durch weitere Angebote angesprochen werden können. 
Zu dem Umfeld der Angelsportbetreibenden gab die Umfrage, Auskunft darüber das 50 % der Zielgruppe in Mittel,-oder Großstädten leben, sowie der Großteil der Befragten (33 %), entweder in einem Haushalt mit Partner und Kindern oder 29 % mindestens in einem Haushalt mit Partner leben. Ebenfalls aufschlussreich für die spätere Unternehmensentwicklung war die Angabe das 36 % der Zielgruppe einen hohen Wert auf Sicherheit & Stabilität legen, dies muss besonders im Rahmen der Funktionserweiterungen und Ausfallsicherheit der App, sowie Datenkonsistenz und Datenschutz mitberücksichtigt werden. Angaben zur Interaktion der Nutzergruppen waren besonders hilfreich für das Verständnis zum Konsumentenverhalten. So bieten Angaben wie, 59 % der Zielgruppe nutzen häufig Online-Shops, eine Chance für Anglers Paradise ein Shopsystem für Angelausrüstung,-& Bedarf zu integrieren, welches ein enormes Potenzial für Umsatzsteigerungen darstellt. 
Aber auch Angaben zum Kontaktverhalten zu Unternehmen und anderen Nutzern sorgten für ein besseres Verständnis der Zielgruppenbedürfnisse,-& Anforderungen. So ergab die Umfrage das 69 % der Befragten eher den direkten Kontakt zu Anbieter über private Nachrichten auf deren Social-Media Plattformen suchen. Des Weiteren kommentiert die Mehrheit der Befragten häufig Bilder & Videos andere Nutzer & teilt selbst Foto,-& Videomaterial. Der Trend zum Communitybuilding der Zielgruppe, ist demnach klar erkennbar und wird deshalb in Anglers Paradise durch verschiedene Features unterstützt. Zu den am häufigsten genutzten Devices der Nutzer zählen zudem mit 96 % das Smartphone, sowie mit 62 % das Tablet. Auch hier sind die Angaben erneut eine optimale Voraussetzung dafür, die angestrebte Zielgruppe mit einer Handyapplikation zu erreichen. Die Zielgruppe selbst, zeichnet sich durch einen hohen Anteil von 73 % männlichen Angelsportbetreibenden aus und ist mit 48 % der Nutzer mit einem durchschnittlichen Alter zwischen 40-64 Jahren gekennzeichnet. Besonders die demografischen Merkmale der Zielgruppe, sind mit Hinblick auf intuitive Bedienungsoberflächen und Suchalgorithmen, in den Designprozess der Appentwicklung miteingeflossen. 

Nachdem es dem Start-Up mit Hilfe der AEIOU-Methode gelungen ist seine Nutzer kennenzulernen und zu identifizieren, wurden Entscheidungen im Designprozess maßgeblich angepasst. Die Angaben der Zielgruppe waren eine zusätzliche Inspirationsquelle und Grundlage, um eine möglichst nutzerfreundliche Applikation zu entwickeln. Aber auch zukünftige Marketingstrategien lassen sich durch die tiefen Einblicke in das Nutzerverhalten und den Nutzer selbst aus dem AEIOU-Framework ableiten und zukünftig umsetzen. 
8 Nutzergruppenzentrierung mit der Jobs-to-be-done-Methode
Um Anglers Paradise demnach erfolgreich auf dem Markt zu etablieren und langfristig erfolgreich zu sein, ist es von höchster Bedeutung eine hohe Nutzerzentrierung zu erzielen. Der maßgebliche Erfolg der App steht also im direkten Zusammenhang mit der Akzeptanz der Endnutzer. Ein Ziel von Anglers Paradise ist es also, auf die Bedürfnisse und Wünsche der Endnutzer einzugehen und als positives und unterstützendes Medium zur Gestaltung der Freizeitaktivitäten und Ausübung des Hobbys wahrgenommen zu werden. Grundlage dafür bildeten Entwicklungsprozesse und Methoden angelehnt an das Design Thinking Prinzip. „Design Thinking ... ist erfinderisches Denken mit radikaler Kunden- beziehungsweise Nutzerorientierung. Es basiert auf dem Prinzip der Interdisziplinarität und verbindet in einem strukturierten, moderierten Iterationsprozess die Haltung der Ergebnisoffenheit mit der Notwendigkeit der Ergebnisorientierung“ (Erbeldinger & Ramge, 2015, S.13). Die Herausforderung ist es also, eine App zu entwickeln, die sich konsequent an den Nutzern und deren Bedürfnisse orientiert und eine Lösung für bestehende Probleme bereitstellt. 
Hierzu gibt es im Design Thinking Bereich, verschiedene Methoden, um ein höheres Kundenverständnis zu erlangen. Mit der Jobs-to-be-done (JTBD)-Methode von Clayton Christensen war es dem Unternehmen möglich sich auf den Nutzer zu fokussieren und neue Erkenntnisse zu gewinnen. Der Ansatz der JTBD-Methode, liegt in der Annahme das Kunden nach einem Produkt oder einer Dienstleistung verlangen, wenn sie eine bestimmte Aufgabe lösen müssen. Es geht also vor allem darum, so Lewrick et.al (2019, S.75) „...die tieferliegenden sozialen, emotionalen oder persönlichen Aufgaben der Kunden zu befriedigen“. Hierzu werden die indirekten Aufgaben und Ziele, die der potenzielle Nutzer hat, erfasst um so strukturiert, neues Wissen über den Kunden zu erlangen und daraus mögliche Kundenbedürfnisse abzuleiten. „Wenn die Aufgaben, die ein Kunde zu erledigen hat, in der Tiefe verstanden sind, dann ist das Erfolgspotenzial nahezu garantiert“ so, Lewrick et.al (2019, S.75). 
Nach erfolgreicher Anwendung der JTBD-Methode, konnte das Unternehmen Anglers Paradise die wesentlichen Nutzeraufgaben-, & Ziele identifizieren und hat somit die Chance mit ihrem Produkt eine kundenorientierte Wertschöpfung zu schaffen. Der JTBD-Ansatz hat es dem Unternehmen möglich gemacht, ein ganzheitliches Verständnis für die Bedürfnisse und Herausforderungen der zentralen Nutzergruppe zu generieren und war maßgeblich Grundlage für die Erlangung einer zukünftigen Marktopportunität. Besonders die strukturierte Aufteilung der Aufgaben, die ein zukünftiger Kunde zu bewältigen hat, bilden eine gute Basis, um daraus die Customer Journey für den Nutzer abzuleiten. Bei der Identifizierung der Nutzeraufgaben, wurden deshalb bewusst nur diejenigen betrachtet, welche bereits in direktem Zusammenhang mit der App stehen. Entscheidungsprozesse und externe Einflussnahmen zur Bedürfniswahrnehmung durch den Nutzer, wurden dabei nur sekundär betrachtet.  Ein Auszug des JTBD-Frameworks und die Anwendung der Methode kann in der nachfolgenden Tabelle (Tab.3) nachvollzogen werden.
Tab.3: Anwendung der JTBD-Methode 
Wenn ich 	will ich 	So kann ich
ein neues Outdoor-Hobby suche	etwas Ruhiges und entspanntes.	Abschalten.
mich für das Angeln entscheide	alle Informationen gebündelt erhalten.	möglichst schnell und unkompliziert beginnen.
Anglers Paradise herunterlade	eine benutzerfreundliche und intuitiv zu bedienende Oberfläche.	alles schnell finden und brauche nicht ewig für die Suche.
in der App einen Kauf tätige	ein schnelles und unkompliziertes Bezahlsystem.	den Kauf schneller abwickeln.
in der App ein Produkt suche	möglichst passende Produktvorschläge.	schneller finden, was ich suche.
in der App ein Nutzerprofil anlege	möglichst viele Features, um ein persönliches Profil zu erstellen das mich präsentiert.	mich mit Gleichgesinnten vernetzen und in den Austausch gehen.
zu meinem gebuchten Angelausflug fahre	will ich alle Informationen, die mir Anglers Paradise zur Verfügung stellt, nutzen.	mein Angelerlebnis optimieren und meine Fangquote erhöhen.
ein Problem mit einer Buchung oder Bestellung habe	einen schnellen und kompetenten Kundensupport.	mein Problem schnell beheben und eine Lösung finden.
den Newsletter abonniere	regelmäßige Rabattaktionen und Eventinformationen.	Geld sparen und bleibe immer auf dem aktuellen Stand.
Quelle: Eigene Darstellung 



9 Customer Journey
Nachdem das Start-Up Anglers Paradise seine Nutzergruppen abschließend identifiziert und mit der JTBD-Methode die Grundlage für die Nutzerzentrierung geschaffen hat, wurde im Anschluss dessen, eine Customer Journey entwickelt. Hierzu waren die im Vorfeld definierten Aufgaben im JTBD-Framework eine große Hilfe. Um Empathie für die Reise des Kunden im Rahmen des Kaufentscheidungsprozesses zu entwickeln, wurden die einzelnen Berührungspunkte, auch Touchpoints genannt, die der Kunde mit dem Unternehmen, sowie der App zukünftig hat, ausgearbeitet. Dabei ist die Customer Journey als eine Art Navigationssystem durch die eigene Unternehmenswelt zu verstehen. Sie betrachtet alle Touchpoints die der zukünftige Nutzer mit dem eigenen Produkt oder der Dienstleistung sowohl direkt als auch indirekt hat. 
Die Kundenreise lässt sich in drei Phasen aufteilen, dabei wird zunächst die Vorkauf-Phase betrachtet. In dieser geht es zunächst primär um die Bedürfniswahrnehmung nach einem bestimmten Produkt. Der Kunde stellt einen subjektiven Mangel fest, man spricht in dieser Situation auch von der Motivation. Motivation bezeichnet dabei eine innere Antriebskraft, die das Verhalten auf ein bestimmtes, zu erreichendes Ziel ausrichtet (Meffert et.al, 2015). Die Bedürfniswahrnehmung wird daher in der Customer Journey und der Vorkauf-Phase unter dem Punkt der „Awareness“ beschrieben. Aus der Motivation heraus den festgestellten Mangel zu beseitigen, folgt der Prozess der Consideration (Erwägung, Überlegung). Der potenzielle Kunde informiert sich über verschiedene Anbieter, vergleicht Angebote und tauscht sich möglicherweise mit weiteren Nutzern aus, die bereits Erfahrungen mit dem Produkt oder der Dienstleistung haben. Während diesem Prozess kommt es bereits zu einer endgültigen Entscheidung für einen Anbieter, um das gewünschte Produkt zu beziehen. 
Nachdem sich ein Konsument also für einen Anbieter entschieden hat, tritt die zweite Phase, die Kauf-Phase ein. Der Kunde kauft ein Produkt oder bucht eine Dienstleistung. Es kommt nach dem Erhalt, zum eigentlichen Nutzen oder Konsumieren. In dieser Phase entscheidet sich bereits, ob der Nutzer erneut bei dem entsprechenden Anbieter kaufen würde. Deshalb wird diese Phase auch Nachkauf-Phase genannt. Im Service-Prozess hat das Unternehmen oder der Anbieter nun die Chance den Kunden durch gezieltes Marketing, erneut zu einem Kauf zu bewegen. Einladungen zu Kurzumfragen, geben dem Kunden die Möglichkeit sowohl das Produkt als auch das Erlebte mit dem Unternehmen, zu bewerten und sind Grundlage für ein besseres, tiefgreifendes Verständnis für die Customer Experience. 

Wurden die Anforderungen des Nutzers erfüllt und die Vorstellungen möglicherweise sogar übertroffen, kommt es im besten Fall zum Eintritt in einen Loyalty Loop. Der Kunde kauft oder bucht regelmäßig ein Produkt oder eine Dienstleistung bei dem Unternehmen und nimmt weitere Angebote wie Newsletter oder Clubmitgliedschaften war. 
Der Verlauf der einzelnen Phasen, steht in unmittelbarem Zusammenhang zu den Touchpoints die der Kunde mit dem Unternehmen hat. Hierbei werden Touchpoints generell in vier Kategorien aufgeteilt. Brand-owned Touchpoints beschreiben jede direkte Interaktion, die der Kunde mit dem Unternehmen hat und über dessen Ausgang das Unternehmen vollständig die Kontrolle hat. Das bedeutet, jeder Berührungspunkt zum Unternehmen ist von diesem selbst konzipiert. Dazu gehören unter anderem Marketingstrategien,-& Maßnahmen wie Werbeplakate, Anzeigen oder bezahlte Partnerschaften mit Influencern, aber auch Produkteigenschaften wie UI/UX-Design der entwickelten App, sowie Preispolitik und Servicemanagement. Partner-owned Touchpoints bezeichnen diejenigen, welche nicht mehr in der direkten Kontrolle des Unternehmens liegen, dennoch durch die aktive Entscheidung bei der Kooperationsauswahl von Partnern gesteuert werden können. Hierzu zählen Marketingagenturen, Anbieter für Zahlungsmöglichkeiten aber auch Verkaufspartner wie bei der Zusammenarbeit von Anglers Paradise mit Anbietern für Angelausrüstung. 
Die Customer Touchpoints, bezeichnen jede Entscheidung und Handlung, die der Kunde selbst vornimmt und sind deshalb für das eigene Unternehmen ein kritischer Berührungspunkt da die Kontrolle über den Ausgang der Interaktion, in der Hand des Kunden liegt. Hierzu zählen sowohl die Bedürfniswahrnehmung als auch die eigenständige Entscheidung für eine Zahlungsmethode. Da diese Interaktionen allerdings auch in Zusammenhang mit den Partner-owned Touchpoints, nämlich dem Anbieter der Zahlungsmethode selbst steht, ist eine isolierte Abgrenzung der Customer Touchpoints vorsichtig zu betrachten.








Die kritischsten Touchpoints sind externe. Sie beziehen sich auf jede Einflussnahme des Kunden durch Dritte. Dazu gehören Rezensionen, Meinungsblogs, dass persönliche Umfeld aber auch die ökonomische Situation und Stabilität eines Landes. Themen wie Inflation oder Rezession haben einen direkten Einfluss auf das Unternehmen selbst und daher unweigerlich auch, auf die Customer Journey und die Customer Experience. Aber auch Negativhaltungen gegenüber dem eigenen Firmenkonzept tragen maßgeblich zu einer veränderten Unternehmenswahrnehmung durch den Nutzer bei. Die anhand dieser Kenntnisse, über die Customer Journey und Touchpoints, beschriebenen Phasen, können daher für Anglers Paradise exemplarisch in der dafür angelegten Customer Journey Map (Abb. 3 & 4), nachvollzogen werden. 
Abb. 5 Customer Journey Anglers Paradise
 
Quelle: Eigene Darstellung



 Abb. 6 Customer Journey Anglers Paradise                                                                                                                                                                          
 Quelle: Eigene Darstellung
9.1 Customer Touchpoint-Management
Wie hoch der Einfluss der einzelnen Touchpoints auf den Kunden und somit die Customer Experience ist, wurde bereits erörtert. Deshalb ist es für das Start-Up Anglers Paradise umso wichtiger durch gezieltes Customer Touchpoint-Management (CTM) ,das Kundenerlebnis stetig zu optimieren und zu verbessern. „Unter Kundenkontaktpunkt-Management (Customer Touchpoint-Management) verstehen wir die Koordination aller unternehmerischen Maßnahmen dergestalt, dass dem Kunden an jedem Iterationspunkt eine herausragende, verlässliche und vertrauenswürdige Erfahrung geboten wird, ohne dabei die Prozesseffizienz aus den Augen zu verlieren“ (Schüller, 2012, S.143). Ziel ist es, loyale Kunden zu gewinnen und diesen ein optimales Kundenerlebnis zu bieten. Um ein geeignetes Touchpoint-Management durchzuführen, braucht es Erfahrungswerte. Hierzu muss ein ganzheitliches Verständnis für die vorhandenen Touchpoints vorliegen. Das heißt, zukünftig ist es für das Start-Up essenziell herauszufiltern, welche Touchpoints wie genutzt werden und welche Relevanz die einzelnen Berührungspunkte bei der Interaktion des Kunden mit dem Unternehmen haben. So müssen regelmäßige Evaluationen und Umfragen durchgeführt werden. 
Dies könnten Zufriedenheitsumfragen zu Themen wie, Paymentanbieter oder Produktqualität der im Shop angebotenen Ausrüstung, Ladeverhalten und Reaktionszeit der Applikation, Erreichbarkeit des Kundensupport und Qualität der Newsletter sein. Aber auch weitere Maßnahmen zur Typisierung der Kundengruppe spielen eine wichtige Rolle für ein erfolgreiches CTM. Hierbei ist es wichtig als Start-Up die einzelnen Kundengruppen abzugrenzen und für diese, eigene Customer Journeys abzuleiten. Dabei spielen sowohl soziodemografische Faktoren eine Rolle, aber auch Erfahrungen und Vorkenntnisse. So entspricht die Customer Journey eines Hobbyangelnden nicht der Customer Journey eines Profiangelnden. Die Touchpoints dieser beiden Kundengruppen hätten zwar mögliche Schnittstellen, würden sich dennoch unterscheiden. So ist ein Profiangelnder möglicherweise nicht so stark auf die Produktvorschläge im Shop angewiesen, da seine Vorkenntnisse zu Ausrüstung und Bedarf deutlich höher sind. Eine größere Rolle könnten dort Touchpoints wie die schnelle und unkomplizierte Suche nach Angelplätzen mittels der Wasserkarten sein. 
Aber auch Datenauswertungen zu Kundenschnittstellen, Kundenzufriedenheit und Unternehmensprozessen, helfen dabei ein umfassendes CTM zu etablieren und die Kundenzufriedenheit der einzelnen Nutzergruppen langfristig zu maximieren. Keller und Ott (2017) fassen die Relevanz eines professionellen CTM wie folgt zusammen:
Wenn Produkte und Services austauschbar sind, worin können sich Unternehmen dann unterscheiden – und können sie ihre Preisgestaltung an diesem Unterschied festmachen? Es bleibt als Unterscheidungskriterium nur das Erlebnis des Kunden bei Kauf oder Nutzung und all den Kontakten, die er auf dem Weg dorthin, während und danach am eigenen Leib erfahren konnte, durchleiden musste oder genießen durfte. (S.33)

9.2 Kundenzufriedenheit
Die zentrale Frage für Anglers Paradise ist demnach: Wie schafft unternehmerisches Handeln, zufriedene Kunden? Um dies beantworten zu können ist zunächst ein Verständnis dafür nötig was zufriedene Kunden auszeichnet. Kundenzufriedenheit zielt grundsätzlich auf die Befriedigung von Kundenbedürfnissen ab. Sie ist der Maßstab für geschäftlichen Erfolg und sorgt für loyale Kunden und die Bereitschaft auch höhere Preise zu zahlen. Somit muss Anglers Paradise vermehrt auf starke und nachhaltige Kundenbeziehungen setzen. Hierzu ist es wichtig den Kunden in jeder Phase der Customer Journey gezielt zu erreichen. 
Während der Vorkauf-Phase, muss der potenzielle Kunde zielgruppenspezifisch vom Unternehmen adressiert werden und ihm sämtliche Informationen zur Verfügung gestellt werden, die seine Kaufentscheidung unmittelbar beeinflussen könnten. 
In der Kauf-Phase ist die schnelle und unkomplizierte Abwicklung des eigentlichen Kaufes durch die Gestaltung der Einkaufsstätte entscheidend. Hier muss Anglers Paradise besonders darauf achten, die Kaufabwicklung im gestalterischen Prozess der App so intuitiv und knapp wie möglich, aber so ausführlich und verständlich wie nötig zu halten. Am entschiedensten für die Kundenbeziehung ist jedoch das Verhalten in der Nachkauf-Phase. Die subjektive Bewertung des Unternehmens durch den Kunden in dieser Phase, ist das Ergebnis ob der Kunde zufrieden oder unzufrieden ist. Um Kundenzufriedenheit im Verständnis für Unternehmen greifbar zu machen, ist es von Vorteil sich dem C/D Paradigma zu bedienen. 
Das Konfirmation/-Diskonfirmations-Paradigma beschreibt vereinfacht, wie Kundenzufriedenheit entsteht, indem es auf der Annahme beruht das ein Nutzer dann zufrieden ist, wenn seine Erwartungen erfüllt wurden. Hierzu vergleicht der Nutzer die subjektiv, empfundene Leistung (Ist-Leistung) mit der objektiven Leistung (Soll-Leistung). Stimmen, Erwartung und tatsächliche Leistung überein, spricht man von Zufriedenheit. Übertrifft die tatsächliche Leistung die Erwartung, ist die Rede von Begeisterung, im schlimmsten Falle für Anglers Paradise, kann die App den Erwartungen des Kunden nicht gerecht werden und er ist unzufrieden. Im Kontext der bisherigen Nutzerzentrierung im Designprozess der App und der Entwicklung der Unternehmensprozesse macht das C/D Paradigma noch einmal deutlich, wie wichtig es ist den zukünftigen Nutzer zu kennen, seine Bedürfnisse zu verstehen und diese möglichst vollständig zu erfüllen.
Um die Kundenzufriedenheit als Unternehmen zu messen, wird zwischen objektiven und subjektiven Verfahren unterschieden. Dabei bedienen sich objektive Verfahren eher an der Bemessung verschiedener Größen und sind unabhängig von der Kundenmeinung. Hierzu zählen Verfahren wie Qualitätskontrollen durch Testkäufe"
